{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ5C/gk6MvSTXlxyxe1krn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emmanuel10701/LangChain-Superstation-A-Comprehensive-Guide-to-Modern-LLM-Frameworks/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u1lRXUQUImZj",
        "outputId": "911a7106-9b12-49b1-d489-ce3c875113ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.4.1 requires google-ai-generativelanguage==0.4.0, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Cannot install langchain==0.1.0 and langchain_core==0.1.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.3.31 requires langchain-core<2.0.0,>=0.3.78, but you have langchain-core 0.1.53 which is incompatible.\n",
            "langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.1.53 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 0.1.53 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m‚ö†Ô∏è Warning: Using fallback memory classes\n",
            "üîê Setting up credentials...\n",
            "‚úÖ Credentials setup complete!\n",
            "üöÄ Starting Enhanced Flight Document Assistant...\n",
            "============================================================\n",
            "‚úÖ LLM and Embedding models initialized!\n",
            "‚úÖ Flight Chat Assistant initialized with enhanced reasoning!\n",
            "\n",
            "ü§ñ ENHANCED FLIGHT ASSISTANT READY!\n",
            "\n",
            "Available Commands:\n",
            "/upload - Upload a document\n",
            "/status - Check document status\n",
            "/clear - Clear conversation memory\n",
            "/quit - Exit the application\n",
            "\n",
            "You can also:\n",
            "- Ask questions about your documents (e.g., \"What is the booking reference?\")\n",
            "- Search for flight information (e.g., \"Extract flight info for Miami\")\n",
            "- Send flight details via email (e.g., \"Send flight details to john@test.com to Miami\")\n",
            "    \n",
            "============================================================\n",
            "\n",
            "üë§ You: hello\n",
            "ü§ñ Assistant: Hello! How can I help you with your flight arrangements today?\n",
            "\n",
            "üë§ You: yeah\n",
            "ü§ñ Assistant: Okay. Do you have a specific request, like finding flight information or sending flight details?\n",
            "\n",
            "üë§ You: /upload\n",
            "üì§ Please upload your document...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c9d22885-cc37-488d-81ba-cbbf5f8b9a7a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c9d22885-cc37-488d-81ba-cbbf5f8b9a7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_flight_info.pdf to sample_flight_info (1).pdf\n",
            "üìÑ ‚úÖ Document 'sample_flight_info (1).pdf' processed successfully! (8247 characters)\n",
            "\n",
            "üë§ You: get all flight data for me\n",
            "ü§ñ Assistant: \n",
            "[Tool Action: extract_flight_info('')]\n",
            "\n",
            "[Tool Action: check_document_status('')]\n",
            "Okay, I see that you have uploaded a document with flight information. How can I help you with it? For example, would you like me to extract information about a specific destination, or send the flight details to someone?\n",
            "\n",
            "üë§ You: any one associated to JFK newyok\n",
            "ü§ñ Assistant: \n",
            "[Tool Action: extract_flight_info('JFK New York')]\n",
            "\n",
            "[Tool Action: extract_flight_info('')]\n",
            "\n",
            "[Tool Action: extract_flight_info('')]\n",
            "I am sorry, I am having trouble extracting the flight data at the moment. Please try again later.\n",
            "\n",
            "üë§ You: okay send me email explaing the issue that you faced and this is the email emmanuelmakau53Ggmail.com\n",
            "ü§ñ Assistant: \n",
            "[Tool Action: send_flight_email('emmanuelmakau53@gmail.com to Issue Explanation')]\n",
            "I am still experiencing issues with extracting the flight data. I am unable to send an email with the flight information at this time. Please try again later.\n",
            "\n",
            "üë§ You: not the flight infromation but just send me the conversation hostory not the infromation based on flight\n",
            "ü§ñ Assistant: I am sorry, I cannot send email with the conversation history. My current capabilities only allow me to send flight details via email.\n",
            "\n",
            "\n",
            "ü§ñ Session ended. Goodbye! üëã\n"
          ]
        }
      ],
      "source": [
        "# Install required dependencies with compatible versions\n",
        "!pip install -q langchain langchain_community langchain-google-genai llama-index pypdf2 python-dotenv\n",
        "!pip install -q langchain==0.1.0 langchain-community==0.0.10 langchain-google-genai==0.0.11 pypdf2 python-dotenv langchain_core==0.1.0\n",
        "!pip install -q \"llama-index>=0.10.0\" \"llama-index-embeddings-huggingface>=0.1.0\" \"llama-index-llms-langchain>=0.1.0\"\n",
        "!pip install -q \"langchain-google-genai==0.0.11\" # Ensure the package is installed with a specific version\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import json\n",
        "import smtplib\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "from datetime import datetime\n",
        "import base64\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "\n",
        "# LangChain core imports\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# FIXED MEMORY IMPORTS\n",
        "try:\n",
        "    from langchain.memory import ConversationBufferWindowMemory, ChatMessageHistory\n",
        "except ImportError:\n",
        "    try:\n",
        "        from langchain_community.memory import ConversationBufferWindowMemory, ChatMessageHistory\n",
        "    except ImportError:\n",
        "        try:\n",
        "            from langchain.memory import ConversationBufferMemory, ChatMessageHistory\n",
        "            ConversationBufferWindowMemory = ConversationBufferMemory\n",
        "            print(\"‚ö†Ô∏è Warning: Using ConversationBufferMemory instead of ConversationBufferWindowMemory\")\n",
        "        except ImportError:\n",
        "            # Final fallback - create a simple mock class\n",
        "            class ConversationBufferWindowMemory:\n",
        "                def __init__(self, k=10, return_messages=True, memory_key=\"chat_history\"):\n",
        "                    self.k = k\n",
        "                    self.return_messages = return_messages\n",
        "                    self.memory_key = memory_key\n",
        "                    self.buffer = []\n",
        "                    self.chat_history = []\n",
        "\n",
        "                @property\n",
        "                def buffer_as_messages(self):\n",
        "                    return self.chat_history\n",
        "\n",
        "                def save_context(self, inputs, outputs):\n",
        "                    user_msg = HumanMessage(content=inputs.get(\"input\", \"\"))\n",
        "                    ai_msg = AIMessage(content=outputs.get(\"output\", \"\"))\n",
        "                    self.chat_history.extend([user_msg, ai_msg])\n",
        "                    # Keep only last k*2 messages (k pairs)\n",
        "                    if len(self.chat_history) > self.k * 2:\n",
        "                        self.chat_history = self.chat_history[-self.k * 2:]\n",
        "\n",
        "                def clear(self):\n",
        "                    self.chat_history = []\n",
        "\n",
        "            class ChatMessageHistory:\n",
        "                def __init__(self):\n",
        "                    self.messages = []\n",
        "\n",
        "                def add_message(self, message):\n",
        "                    self.messages.append(message)\n",
        "\n",
        "                def clear(self):\n",
        "                    self.messages = []\n",
        "\n",
        "            print(\"‚ö†Ô∏è Warning: Using fallback memory classes\")\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# LlamaIndex imports - with error handling\n",
        "try:\n",
        "    from llama_index.core import VectorStoreIndex, Document\n",
        "    from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "    from llama_index.llms.langchain import LangChainLLM\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå LlamaIndex import error: {e}\")\n",
        "    print(\"üîÑ Using alternative implementation...\")\n",
        "\n",
        "    # Fallback implementations\n",
        "    class Document:\n",
        "        def __init__(self, text: str = \"\"):\n",
        "            self.text = text\n",
        "\n",
        "    class VectorStoreIndex:\n",
        "        def __init__(self, documents=None, embed_model=None):\n",
        "            self.documents = documents or []\n",
        "            self.embed_model = embed_model\n",
        "\n",
        "        @classmethod\n",
        "        def from_documents(cls, documents, embed_model):\n",
        "            return cls(documents=documents, embed_model=embed_model)\n",
        "\n",
        "        def as_query_engine(self, llm=None):\n",
        "            class QueryEngine:\n",
        "                def __init__(self, documents, llm):\n",
        "                    self.documents = documents\n",
        "                    self.llm = llm\n",
        "\n",
        "                def query(self, query):\n",
        "                    if self.documents and hasattr(self.documents[0], 'text'):\n",
        "                        doc_text = self.documents[0].text\n",
        "                        return f\"Mock response for: {query}\\nDocument content: {doc_text[:200]}...\"\n",
        "                    return \"No documents available\"\n",
        "\n",
        "            return QueryEngine(self.documents, llm)\n",
        "\n",
        "    class HuggingFaceEmbedding:\n",
        "        def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "            self.model_name = model_name\n",
        "\n",
        "    class LangChainLLM:\n",
        "        def __init__(self, llm):\n",
        "            self.llm = llm\n",
        "\n",
        "\n",
        "# File upload for Colab compatibility\n",
        "try:\n",
        "    from google.colab import files\n",
        "except ImportError:\n",
        "    # Define a dummy function for non-Colab environments\n",
        "    def files():\n",
        "        class DummyFiles:\n",
        "            def upload(self):\n",
        "                print(\"‚ö†Ô∏è File upload not supported outside Google Colab environment.\")\n",
        "                return {}\n",
        "        return DummyFiles()\n",
        "\n",
        "# Configuration and Credentials Setup\n",
        "print(\"üîê Setting up credentials...\")\n",
        "\n",
        "# You'll need to input these values\n",
        "GEMINI_API_KEY = \"AIzaSyAp1ukyhvL2_CkFsMMOCo1ZClxk2a0lepE\" # @param {type:\"string\"}\n",
        "EMAIL_ADDRESS = \"emmanuelmakau90@gmail.com\" # @param {type:\"string\"}\n",
        "EMAIL_PASSWORD = \"skcc fklt twxl bbht\" # @param {type:\"string\"}\n",
        "SMTP_SERVER = \"smtp.gmail.com\" # @param {type:\"string\"}\n",
        "SMTP_PORT = 587 # @param {type:\"integer\"}\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
        "\n",
        "# Validate credentials\n",
        "if not GEMINI_API_KEY:\n",
        "    print(\"‚ùå Please enter your Gemini API Key\")\n",
        "if not EMAIL_ADDRESS or not EMAIL_PASSWORD:\n",
        "    print(\"‚ùå Please enter your email credentials\")\n",
        "\n",
        "print(\"‚úÖ Credentials setup complete!\")\n",
        "\n",
        "class EmailService:\n",
        "    \"\"\"Service for sending email notifications with dynamic templates\"\"\"\n",
        "\n",
        "    def __init__(self, email: str, password: str, smtp_server: str = \"smtp.gmail.com\", smtp_port: int = 587):\n",
        "        self.email = email\n",
        "        self.password = password\n",
        "        self.smtp_server = smtp_server\n",
        "        self.smtp_port = smtp_port\n",
        "        self.template_llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-2.0-flash-exp\",\n",
        "            google_api_key=GEMINI_API_KEY,\n",
        "            temperature=0.8,  # Higher temperature for creative email templates\n",
        "            max_output_tokens=2048,\n",
        "            convert_system_message_to_human=True\n",
        "        )\n",
        "\n",
        "    def _generate_dynamic_email_template(self, flight_details: Dict[str, Any], recipient: str = \"Traveler\") -> str:\n",
        "        \"\"\"Generate a dynamic, modern email template using AI\"\"\"\n",
        "\n",
        "        template_prompt = f\"\"\"\n",
        "        Create a modern, professional, and visually appealing email template for flight details.\n",
        "        Use emojis sparingly for visual appeal and create a clean, mobile-responsive design using plain text formatting.\n",
        "\n",
        "        Flight Information:\n",
        "        - Passenger: {flight_details.get('passenger_name', 'Traveler')}\n",
        "        - Flight: {flight_details.get('flight_number', 'N/A')}\n",
        "        - Route: {flight_details.get('departure_airport', 'N/A')} ‚Üí {flight_details.get('arrival_airport', 'N/A')}\n",
        "        - Date: {flight_details.get('departure_date', 'N/A')} at {flight_details.get('departure_time', 'N/A')}\n",
        "        - Booking Reference: {flight_details.get('booking_reference', 'N/A')}\n",
        "        - Seat: {flight_details.get('seat_number', 'N/A')} ({flight_details.get('class', 'N/A')})\n",
        "\n",
        "        Create a template that includes:\n",
        "        1. A professional header\n",
        "        2. Clear flight itinerary with emphasis on key times\n",
        "        3. Important travel reminders\n",
        "        4. Contact information section\n",
        "        5. Friendly closing\n",
        "\n",
        "        Format it beautifully using plain text with strategic spacing, lines, and emphasis.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.template_llm.invoke([HumanMessage(content=template_prompt)])\n",
        "            return response.content\n",
        "        except Exception as e:\n",
        "            # Fallback template if AI generation fails\n",
        "            return self._create_fallback_template(flight_details)\n",
        "\n",
        "    def _create_fallback_template(self, flight_details: Dict[str, Any]) -> str:\n",
        "        \"\"\"Create a beautiful fallback template\"\"\"\n",
        "        return f\"\"\"\n",
        "üåü FLIGHT CONFIRMATION üåü\n",
        "\n",
        "Dear {flight_details.get('passenger_name', 'Traveler')},\n",
        "\n",
        "Here are your flight details for your upcoming journey:\n",
        "\n",
        "‚úàÔ∏è FLIGHT ITINERARY\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "üõ´ DEPARTURE\n",
        "‚Ä¢ Airport: {flight_details.get('departure_airport', 'N/A')}\n",
        "‚Ä¢ Date: {flight_details.get('departure_date', 'N/A')}\n",
        "‚Ä¢ Time: {flight_details.get('departure_time', 'N/A')}\n",
        "‚Ä¢ Flight: {flight_details.get('flight_number', 'N/A')}\n",
        "\n",
        "üõ¨ ARRIVAL\n",
        "‚Ä¢ Airport: {flight_details.get('arrival_airport', 'N/A')}\n",
        "‚Ä¢ Date: {flight_details.get('arrival_date', 'N/A')}\n",
        "‚Ä¢ Time: {flight_details.get('arrival_time', 'N/A')}\n",
        "\n",
        "üë§ PASSENGER DETAILS\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "‚Ä¢ Name: {flight_details.get('passenger_name', 'N/A')}\n",
        "‚Ä¢ Booking Reference: {flight_details.get('booking_reference', 'N/A')}\n",
        "‚Ä¢ Seat: {flight_details.get('seat_number', 'N/A')} ({flight_details.get('class', 'N/A')})\n",
        "\n",
        "üìã TRAVEL TIPS\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "‚Ä¢ Check in online 24 hours before departure\n",
        "‚Ä¢ Arrive at the airport 2-3 hours before your flight\n",
        "‚Ä¢ Have your ID and travel documents ready\n",
        "‚Ä¢ Keep this confirmation handy\n",
        "\n",
        "Safe travels and enjoy your flight! ‚úàÔ∏è\n",
        "\n",
        "Warm regards,\n",
        "Your Travel Assistant\n",
        "\"\"\"\n",
        "\n",
        "    def send_flight_email(self, to_email: str, flight_details: Dict[str, Any], subject: str = \"Flight Details\"):\n",
        "        \"\"\"Send flight details via email with dynamic template\"\"\"\n",
        "        try:\n",
        "            # Create email message\n",
        "            msg = MIMEMultipart()\n",
        "            msg['From'] = self.email\n",
        "            msg['To'] = to_email\n",
        "            msg['Subject'] = subject\n",
        "\n",
        "            # Generate dynamic email body\n",
        "            body = self._generate_dynamic_email_template(flight_details, to_email)\n",
        "\n",
        "            msg.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "            # Send email\n",
        "            server = smtplib.SMTP(self.smtp_server, self.smtp_port)\n",
        "            server.starttls()\n",
        "            server.login(self.email, self.password)\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "\n",
        "            return f\"‚úÖ Flight details email sent successfully to {to_email}!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            if 'authentication failed' in str(e).lower():\n",
        "                return f\"‚ùå Failed to send email: Authentication failed. Check your EMAIL_PASSWORD (must be an App Password).\"\n",
        "            return f\"‚ùå Failed to send email: {str(e)}\"\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"Handles document processing and RAG implementation\"\"\"\n",
        "\n",
        "    def __init__(self, gemini_api_key: str):\n",
        "        self.gemini_api_key = gemini_api_key\n",
        "        self.uploaded_documents = {}\n",
        "        self.document_index = None\n",
        "        self.setup_llm()\n",
        "\n",
        "    def setup_llm(self):\n",
        "        \"\"\"Setup Gemini LLM and embedding model\"\"\"\n",
        "        try:\n",
        "            # Initialize Gemini with better thinking temperature\n",
        "            self.llm = ChatGoogleGenerativeAI(\n",
        "                model=\"gemini-2.0-flash-exp\",\n",
        "                google_api_key=self.gemini_api_key,\n",
        "                temperature=0.4,  # Balanced temperature for reasoning\n",
        "                max_output_tokens=2048,\n",
        "                convert_system_message_to_human=True,  # Fix for system message issue\n",
        "                verbose=False\n",
        "            )\n",
        "\n",
        "            # Setup embedding model\n",
        "            self.embed_model = HuggingFaceEmbedding(\n",
        "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "            )\n",
        "\n",
        "            print(\"‚úÖ LLM and Embedding models initialized!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to initialize models: {e}\")\n",
        "\n",
        "    def process_document(self, file_path: str) -> str:\n",
        "        \"\"\"Process uploaded document and create vector index\"\"\"\n",
        "        try:\n",
        "            # Read document\n",
        "            if file_path.endswith('.pdf'):\n",
        "                text = self._extract_pdf_text(file_path)\n",
        "            elif file_path.endswith('.txt'):\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    text = f.read()\n",
        "            else:\n",
        "                return \"‚ùå Unsupported file format. Use PDF or TXT.\"\n",
        "\n",
        "            if not text:\n",
        "                return \"‚ùå No text extracted from document.\"\n",
        "\n",
        "            # Store document text\n",
        "            filename = os.path.basename(file_path)\n",
        "            self.uploaded_documents[filename] = text\n",
        "\n",
        "            # Create LlamaIndex documents\n",
        "            llama_documents = [Document(text=text)]\n",
        "\n",
        "            # Create vector index\n",
        "            self.document_index = VectorStoreIndex.from_documents(\n",
        "                documents=llama_documents,\n",
        "                embed_model=self.embed_model\n",
        "            )\n",
        "\n",
        "            return f\"‚úÖ Document '{filename}' processed successfully! ({len(text)} characters)\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Document processing error: {str(e)}\"\n",
        "\n",
        "    def _extract_pdf_text(self, file_path: str) -> str:\n",
        "        \"\"\"Extract text from PDF files\"\"\"\n",
        "        try:\n",
        "            import PyPDF2\n",
        "            with open(file_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                text = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        text += page_text + \"\\n\"\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"PDF extraction failed: {str(e)}\")\n",
        "\n",
        "    def search_documents(self, query: str) -> str:\n",
        "        \"\"\"Search through processed documents using RAG\"\"\"\n",
        "        if not self.document_index:\n",
        "            return \"‚ùå No documents processed yet. Please upload a document first.\"\n",
        "\n",
        "        try:\n",
        "            # Create query engine\n",
        "            query_engine = self.document_index.as_query_engine(\n",
        "                llm=LangChainLLM(llm=self.llm)\n",
        "            )\n",
        "\n",
        "            # Execute query\n",
        "            response = query_engine.query(query)\n",
        "            return str(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Search error: {str(e)}\"\n",
        "\n",
        "    def extract_flight_info(self, destination: str = None) -> Dict[str, Any]:\n",
        "        \"\"\"Extract flight information from documents with better reasoning\"\"\"\n",
        "        if not self.document_index:\n",
        "            return {\"error\": \"No documents processed\"}\n",
        "\n",
        "        try:\n",
        "            # Enhanced query for better extraction\n",
        "            query = \"\"\"\n",
        "            Carefully analyze the document and extract ALL flight information with high accuracy.\n",
        "            Look for:\n",
        "            - Flight numbers (typically codes like BA123, AA456, etc.)\n",
        "            - Airport codes (3-letter codes like LHR, JFK, LAX)\n",
        "            - Full airport names\n",
        "            - Dates in various formats (YYYY-MM-DD, DD/MM/YYYY, etc.)\n",
        "            - Times (24-hour or 12-hour format)\n",
        "            - Passenger names (title + first + last name)\n",
        "            - Booking/confirmation references (typically 6-8 alphanumeric characters)\n",
        "            - Seat numbers (like 12A, 15C, 24F)\n",
        "            - Class (Economy, Business, First, Premium Economy)\n",
        "\n",
        "            Return the most complete and accurate information found.\n",
        "            \"\"\"\n",
        "\n",
        "            if destination:\n",
        "                query += f\"\\nFocus specifically on flights to or involving: {destination}\"\n",
        "\n",
        "            flight_query_engine = self.document_index.as_query_engine(\n",
        "                llm=LangChainLLM(llm=self.llm)\n",
        "            )\n",
        "\n",
        "            response = flight_query_engine.query(query)\n",
        "\n",
        "            flight_info = self._parse_flight_response(str(response))\n",
        "\n",
        "            return flight_info\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Flight extraction failed: {str(e)}\"}\n",
        "\n",
        "    def _parse_flight_response(self, response: str) -> Dict[str, Any]:\n",
        "        \"\"\"Parse LLM response to extract structured flight data\"\"\"\n",
        "        flight_info = {\n",
        "            \"flight_number\": \"Not specified\", \"departure_airport\": \"Not specified\",\n",
        "            \"arrival_airport\": \"Not specified\", \"departure_date\": \"Not specified\",\n",
        "            \"departure_time\": \"Not specified\", \"arrival_date\": \"Not specified\",\n",
        "            \"arrival_time\": \"Not specified\", \"passenger_name\": \"Not specified\",\n",
        "            \"booking_reference\": \"Not specified\", \"seat_number\": \"Not specified\",\n",
        "            \"class\": \"Not specified\", \"additional_info\": response[:500]\n",
        "        }\n",
        "\n",
        "        # Enhanced parsing with better patterns\n",
        "        lines = response.split('\\n')\n",
        "        for line in lines:\n",
        "            line_lower = line.lower()\n",
        "\n",
        "            def get_value(line_input):\n",
        "                parts = line_input.split(':', 1)\n",
        "                if len(parts) > 1:\n",
        "                    return parts[1].strip()\n",
        "                # Try other separators\n",
        "                for sep in ['-', '=', '->']:\n",
        "                    if sep in line_input:\n",
        "                        return line_input.split(sep, 1)[1].strip()\n",
        "                return line_input.strip()\n",
        "\n",
        "            # Flight number patterns\n",
        "            if any(keyword in line_lower for keyword in ['flight', 'flight no', 'flight number', 'flt']):\n",
        "                if ':' in line or any(sep in line for sep in ['-', '=', '->']):\n",
        "                    flight_info['flight_number'] = get_value(line)\n",
        "\n",
        "            # Airport patterns\n",
        "            elif any(keyword in line_lower for keyword in ['departure', 'from', 'origin']):\n",
        "                if 'airport' in line_lower or any(code in line.upper() for code in ['LHR', 'JFK', 'LAX', 'CDG', 'DXB']):\n",
        "                    flight_info['departure_airport'] = get_value(line)\n",
        "\n",
        "            elif any(keyword in line_lower for keyword in ['arrival', 'to', 'destination']):\n",
        "                if 'airport' in line_lower or any(code in line.upper() for code in ['LHR', 'JFK', 'LAX', 'CDG', 'DXB']):\n",
        "                    flight_info['arrival_airport'] = get_value(line)\n",
        "\n",
        "            # Passenger name patterns\n",
        "            elif any(keyword in line_lower for keyword in ['passenger', 'name', 'mr', 'ms', 'mrs', 'dr']):\n",
        "                flight_info['passenger_name'] = get_value(line)\n",
        "\n",
        "            # Booking reference patterns\n",
        "            elif any(keyword in line_lower for keyword in ['booking', 'reference', 'confirmation', 'pnr']):\n",
        "                flight_info['booking_reference'] = get_value(line)\n",
        "\n",
        "            # Seat patterns\n",
        "            elif any(keyword in line_lower for keyword in ['seat', 'seat no', 'seat number']):\n",
        "                flight_info['seat_number'] = get_value(line)\n",
        "\n",
        "            # Class patterns\n",
        "            elif any(keyword in line_lower for keyword in ['class', 'cabin', 'travel class']):\n",
        "                flight_info['class'] = get_value(line)\n",
        "\n",
        "        return flight_info\n",
        "\n",
        "class FlightChatAssistant:\n",
        "    \"\"\"Main chat assistant using a direct LLM call for tool routing\"\"\"\n",
        "\n",
        "    def __init__(self, gemini_api_key: str, email_service: EmailService):\n",
        "        self.gemini_api_key = gemini_api_key\n",
        "        self.email_service = email_service\n",
        "        self.document_processor = DocumentProcessor(gemini_api_key)\n",
        "        # Initialize memory using the imported class (which might be a fallback)\n",
        "        self.memory = ConversationBufferWindowMemory(k=10, return_messages=True, memory_key=\"chat_history\")\n",
        "        self.llm = None\n",
        "        self.tool_map = {}\n",
        "        self.setup_llm_and_tools()\n",
        "\n",
        "    def setup_llm_and_tools(self):\n",
        "        \"\"\"Setup the LLM and tool map with better temperature settings\"\"\"\n",
        "        try:\n",
        "            # Initialize LLM with optimized temperature for reasoning\n",
        "            self.llm = ChatGoogleGenerativeAI(\n",
        "                model=\"gemini-2.0-flash-exp\",\n",
        "                google_api_key=self.gemini_api_key,\n",
        "                temperature=0.5,  # Higher temperature for better reasoning and creativity\n",
        "                max_output_tokens=2048,\n",
        "                convert_system_message_to_human=True,  # Fix system message issue\n",
        "                verbose=False\n",
        "            )\n",
        "\n",
        "            # Define tool functions and map them\n",
        "            self.tools = [\n",
        "                Tool(\n",
        "                    name=\"document_search\",\n",
        "                    func=self._search_documents_tool,\n",
        "                    description=\"Search through uploaded documents for specific information. Input should be a search query (string).\"\n",
        "                ),\n",
        "                Tool(\n",
        "                    name=\"extract_flight_info\",\n",
        "                    func=self._extract_flight_info_tool,\n",
        "                    description=\"Extract flight information from uploaded documents. Input should be the destination (string) like 'Miami' or an empty string for all flights.\"\n",
        "                ),\n",
        "                Tool(\n",
        "                    name=\"send_flight_email\",\n",
        "                    func=self._send_flight_email_tool,\n",
        "                    description=\"Send flight details via email. Input format: 'recipient@email.com to Destination' (string) like 'john@email.com to Miami'\"\n",
        "                ),\n",
        "                Tool(\n",
        "                    name=\"check_document_status\",\n",
        "                    func=self._check_document_status_tool,\n",
        "                    description=\"Check if documents are uploaded and processed. Input can be an empty string.\"\n",
        "                )\n",
        "            ]\n",
        "\n",
        "            # Create a simple mapping of tool names to their function references\n",
        "            for tool in self.tools:\n",
        "                self.tool_map[tool.name] = tool.func\n",
        "\n",
        "            print(\"‚úÖ Flight Chat Assistant initialized with enhanced reasoning!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå LLM setup failed: {e}\")\n",
        "            self.llm = None\n",
        "\n",
        "    def _get_system_prompt_for_tool_routing(self):\n",
        "        \"\"\"Generates a ReAct-style system prompt for direct tool call logic\"\"\"\n",
        "        tool_descriptions = \"\\n\".join([f\"- {t.name}: {t.description}\" for t in self.tools])\n",
        "\n",
        "        # Convert system message to human message format for Gemini compatibility\n",
        "        system_content = f\"\"\"You are a helpful Flight Assistant. You have access to the following tools:\n",
        "\n",
        "{tool_descriptions}\n",
        "\n",
        "The user's request will be in the format: '{{input}}'.\n",
        "You MUST follow this exact Thought/Action pattern:\n",
        "\n",
        "1. **Thought**: Reason about the user's request. Decide if a tool is necessary.\n",
        "2. **Action**: If a tool is necessary, output the call in this EXACT format:\n",
        "   'TOOL_CALL: tool_name(\"tool_input\")'\n",
        "   - Example 1 (Search): 'TOOL_CALL: document_search(\"What is the flight number\")'\n",
        "   - Example 2 (Email): 'TOOL_CALL: send_flight_email(\"test@email.com to London\")'\n",
        "3. **Final Answer**: If no tool is needed, or after a tool has been executed, provide the final answer directly.\n",
        "\n",
        "If the user's input is a simple greeting or non-flight question, respond directly.\n",
        "NEVER use a tool unless the information is either in the document or requires sending an email.\"\"\"\n",
        "\n",
        "        return system_content\n",
        "\n",
        "    # Tool methods (The same, but now called directly)\n",
        "    def _search_documents_tool(self, query: str) -> str:\n",
        "        return self.document_processor.search_documents(query)\n",
        "\n",
        "    def _extract_flight_info_tool(self, destination: str = \"\") -> str:\n",
        "        flight_info = self.document_processor.extract_flight_info(destination)\n",
        "        if \"error\" in flight_info:\n",
        "            return flight_info[\"error\"]\n",
        "\n",
        "        formatted_info = \"‚úàÔ∏è Extracted Flight Information:\\n\"\n",
        "        for key, value in flight_info.items():\n",
        "            if key not in [\"additional_info\", \"raw_response\"] and value != \"Not specified\":\n",
        "                formatted_info += f\"‚Ä¢ {key.replace('_', ' ').title()}: {value}\\n\"\n",
        "\n",
        "        formatted_info += f\"\\nAdditional Context:\\n{flight_info.get('additional_info', 'None')}\"\n",
        "        return formatted_info\n",
        "\n",
        "    def _send_flight_email_tool(self, request: str) -> str:\n",
        "        \"\"\"Send flight email - expects format: 'email@example.com to Miami'\"\"\"\n",
        "        try:\n",
        "            # Note: This is simplified parsing for the direct call\n",
        "            parts = request.split(' to ')\n",
        "            if len(parts) != 2:\n",
        "                return \"‚ùå Please specify both email and destination like: 'email@example.com to Miami'\"\n",
        "\n",
        "            email = parts[0].strip()\n",
        "            destination = parts[1].strip()\n",
        "\n",
        "            flight_info = self.document_processor.extract_flight_info(destination)\n",
        "\n",
        "            if \"error\" in flight_info:\n",
        "                return f\"‚ùå Cannot send email: {flight_info['error']}\"\n",
        "\n",
        "            result = self.email_service.send_flight_email(\n",
        "                to_email=email,\n",
        "                flight_details=flight_info,\n",
        "                subject=f\"Flight Details to {destination}\"\n",
        "            )\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Email sending failed: {str(e)}\"\n",
        "\n",
        "    def _check_document_status_tool(self, query: str) -> str:\n",
        "        if not self.document_processor.uploaded_documents:\n",
        "            return \"‚ùå No documents uploaded. Please upload a document first.\"\n",
        "\n",
        "        status = \"üìÑ Uploaded Documents:\\n\"\n",
        "        for doc_name in self.document_processor.uploaded_documents.keys():\n",
        "            status += f\"‚Ä¢ {doc_name}\\n\"\n",
        "\n",
        "        if self.document_processor.document_index:\n",
        "            status += \"\\n‚úÖ Document index is ready for searching!\"\n",
        "        else:\n",
        "            status += \"\\n‚ùå Document index not created.\"\n",
        "\n",
        "        return status\n",
        "\n",
        "    def upload_document(self, file_path: str) -> str:\n",
        "        \"\"\"Upload and process a document\"\"\"\n",
        "        return self.document_processor.process_document(file_path)\n",
        "\n",
        "    def _parse_and_execute_tool_call(self, llm_response: str) -> str:\n",
        "        \"\"\"Parses the LLM's raw text response for a TOOL_CALL and executes it.\"\"\"\n",
        "        match = re.search(r'TOOL_CALL: (.*?)\\(\"?([^\"]*)\"?\\)', llm_response, re.DOTALL)\n",
        "\n",
        "        if match:\n",
        "            tool_name = match.group(1).strip()\n",
        "            tool_input = match.group(2).strip()\n",
        "\n",
        "            print(f\"\\n[Tool Action: {tool_name}('{tool_input}')]\")\n",
        "\n",
        "            if tool_name in self.tool_map:\n",
        "                # Execute the tool and get the result\n",
        "                tool_result = self.tool_map[tool_name](tool_input)\n",
        "\n",
        "                # Recursively call the LLM with the tool result to get the final answer\n",
        "                # The message becomes: \"Tool Result (tool_name): tool_result\"\n",
        "                return self.chat(f\"Tool Result ({tool_name}): {tool_result}\")\n",
        "            else:\n",
        "                return f\"‚ùå Tool not found: {tool_name}\"\n",
        "\n",
        "        # If no tool call, assume the LLM output is the Final Answer\n",
        "        # Find the Final Answer tag if it exists, otherwise return the whole output\n",
        "        final_answer_match = re.search(r'Final Answer:(.*)', llm_response, re.DOTALL)\n",
        "        if final_answer_match:\n",
        "            return final_answer_match.group(1).strip()\n",
        "\n",
        "        # Fallback\n",
        "        return llm_response.strip()\n",
        "\n",
        "    def chat(self, message: str) -> str:\n",
        "        \"\"\"Main chat method using direct LLM call and parsing loop\"\"\"\n",
        "        if self.llm is None:\n",
        "            return \"‚ùå Assistant not properly initialized.\"\n",
        "\n",
        "        # Build the prompt with history - convert system message to human for Gemini\n",
        "        prompt_parts = [\n",
        "            HumanMessage(content=self._get_system_prompt_for_tool_routing()),\n",
        "            *self.memory.buffer_as_messages,\n",
        "            HumanMessage(content=message)\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # Step 1: LLM generates Thought and Action/Final Answer\n",
        "            llm_response_message = self.llm.invoke(prompt_parts)\n",
        "            llm_response = llm_response_message.content\n",
        "\n",
        "            # Step 2: Parse and execute tool\n",
        "            result = self._parse_and_execute_tool_call(llm_response)\n",
        "\n",
        "            # Step 3: Update memory (for simple chat, add both user message and final LLM response)\n",
        "            self.memory.save_context({\"input\": message}, {\"output\": result})\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Chat error: {str(e)}\"\n",
        "\n",
        "# File upload utility for Colab\n",
        "def upload_file():\n",
        "    \"\"\"Upload a file in Colab or return None\"\"\"\n",
        "    try:\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            filename = list(uploaded.keys())[0]\n",
        "            return filename\n",
        "        return None\n",
        "    except NameError:\n",
        "        print(\"‚ö†Ô∏è File upload not available in this environment\")\n",
        "        return None\n",
        "\n",
        "# Main application\n",
        "def main():\n",
        "    \"\"\"Run the flight chat assistant\"\"\"\n",
        "\n",
        "    print(\"üöÄ Starting Enhanced Flight Document Assistant...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize services\n",
        "    if not all([GEMINI_API_KEY, EMAIL_ADDRESS, EMAIL_PASSWORD]):\n",
        "        print(\"‚ùå Please set all required credentials in the configuration section\")\n",
        "        return\n",
        "\n",
        "    email_service = EmailService(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
        "    assistant = FlightChatAssistant(GEMINI_API_KEY, email_service)\n",
        "\n",
        "    print(\"\\nü§ñ ENHANCED FLIGHT ASSISTANT READY!\")\n",
        "    print(\"\"\"\n",
        "Available Commands:\n",
        "/upload - Upload a document\n",
        "/status - Check document status\n",
        "/clear - Clear conversation memory\n",
        "/quit - Exit the application\n",
        "\n",
        "You can also:\n",
        "- Ask questions about your documents (e.g., \"What is the booking reference?\")\n",
        "- Search for flight information (e.g., \"Extract flight info for Miami\")\n",
        "- Send flight details via email (e.g., \"Send flight details to john@test.com to Miami\")\n",
        "    \"\"\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nüë§ You: \").strip()\n",
        "\n",
        "            if user_input.lower() in ['/quit', '/exit', 'quit', 'exit']:\n",
        "                print(\"ü§ñ Goodbye! Safe travels! ‚úàÔ∏è\")\n",
        "                break\n",
        "\n",
        "            elif user_input.startswith('/upload'):\n",
        "                print(\"üì§ Please upload your document...\")\n",
        "                filename = upload_file()\n",
        "                if filename:\n",
        "                    result = assistant.upload_document(filename)\n",
        "                    print(f\"üìÑ {result}\")\n",
        "                else:\n",
        "                    print(\"‚ùå No file uploaded.\")\n",
        "                continue\n",
        "\n",
        "            elif user_input == '/status':\n",
        "                status = assistant._check_document_status_tool(\"\")\n",
        "                print(status)\n",
        "                continue\n",
        "\n",
        "            elif user_input == '/clear':\n",
        "                assistant.memory.clear()\n",
        "                print(\"üßπ Conversation memory cleared!\")\n",
        "                continue\n",
        "\n",
        "            elif not user_input:\n",
        "                continue\n",
        "\n",
        "            # Process regular chat message\n",
        "            print(\"ü§ñ Assistant: \", end=\"\")\n",
        "            response = assistant.chat(user_input)\n",
        "            print(response)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nü§ñ Session ended. Goodbye! üëã\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error: {e}\")\n",
        "\n",
        "# Run the application\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for RAG and embeddings\n",
        "!pip install -q langchain-google-genai pypdf2 python-dotenv sentence-transformers faiss-cpu\n",
        "!pip install -q \"huggingface_hub\" \"tokenizers\" \"transformers\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import smtplib\n",
        "import re\n",
        "from datetime import datetime\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.application import MIMEApplication\n",
        "from typing import Dict, Any, List, Tuple\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
        "\n",
        "try:\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    from langchain.schema import HumanMessage\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "    from langchain.embeddings import HuggingFaceEmbeddings\n",
        "    from langchain.vectorstores import FAISS\n",
        "    from langchain.docstore.document import Document as LangchainDocument\n",
        "    print(\"‚úÖ All LangChain imports successful!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Some imports failed: {e}\")\n",
        "    # Fallbacks\n",
        "    class HumanMessage:\n",
        "        def __init__(self, content):\n",
        "            self.content = content\n",
        "\n",
        "# Modern Email Service with AI-generated HTML templates\n",
        "class ModernEmailService:\n",
        "    def __init__(self, email: str, password: str):\n",
        "        self.email = email\n",
        "        self.password = password\n",
        "        self.setup_llm()\n",
        "\n",
        "    def setup_llm(self):\n",
        "        \"\"\"Setup LLM for generating modern email templates\"\"\"\n",
        "        try:\n",
        "            self.template_llm = ChatGoogleGenerativeAI(\n",
        "                model=\"gemini-2.0-flash-exp\",\n",
        "                google_api_key=GEMINI_API_KEY,\n",
        "                temperature=0.8,\n",
        "                max_output_tokens=4096,\n",
        "                convert_system_message_to_human=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Template LLM setup failed: {e}\")\n",
        "            self.template_llm = None\n",
        "\n",
        "    def generate_modern_flight_email(self, flight_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Generate modern HTML email template using AI\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Create a MODERN, PROFESSIONAL HTML email template for flight details with beautiful styling.\n",
        "\n",
        "        FLIGHT INFORMATION:\n",
        "        {json.dumps(flight_data, indent=2)}\n",
        "\n",
        "        Create a complete HTML email with:\n",
        "        - Modern header with gradient background\n",
        "        - Clean, professional layout\n",
        "        - Flight details in a beautiful card design\n",
        "        - Icons and visual elements using UTF-8 emojis\n",
        "        - Responsive design for mobile devices\n",
        "        - Professional footer\n",
        "\n",
        "        Use modern CSS: gradients, shadows, rounded corners.\n",
        "        Make it look like a professional airline confirmation email.\n",
        "        Return ONLY the HTML code.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            if self.template_llm:\n",
        "                response = self.template_llm.invoke([HumanMessage(content=prompt)])\n",
        "                return response.content\n",
        "            else:\n",
        "                return self._create_fallback_html(flight_data)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå AI template generation failed: {e}\")\n",
        "            return self._create_fallback_html(flight_data)\n",
        "\n",
        "    def _create_fallback_html(self, flight_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Create a beautiful fallback HTML template\"\"\"\n",
        "        passenger = flight_data.get('passenger_name', 'Valued Passenger')\n",
        "        flight_num = flight_data.get('flight_number', 'N/A')\n",
        "        departure = flight_data.get('departure_airport', 'N/A')\n",
        "        arrival = flight_data.get('arrival_airport', 'N/A')\n",
        "        date = flight_data.get('departure_date', 'N/A')\n",
        "        time = flight_data.get('departure_time', 'N/A')\n",
        "        seat = flight_data.get('seat_number', 'N/A')\n",
        "        flight_class = flight_data.get('class', 'N/A')\n",
        "        booking_ref = flight_data.get('booking_reference', 'N/A')\n",
        "\n",
        "        return f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Flight Confirmation</title>\n",
        "    <style>\n",
        "        body {{\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            line-height: 1.6;\n",
        "            color: #333;\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        }}\n",
        "        .container {{\n",
        "            max-width: 600px;\n",
        "            margin: 20px auto;\n",
        "            background: white;\n",
        "            border-radius: 15px;\n",
        "            overflow: hidden;\n",
        "            box-shadow: 0 10px 30px rgba(0,0,0,0.2);\n",
        "        }}\n",
        "        .header {{\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            padding: 30px;\n",
        "            text-align: center;\n",
        "        }}\n",
        "        .header h1 {{\n",
        "            margin: 0;\n",
        "            font-size: 28px;\n",
        "            font-weight: 300;\n",
        "        }}\n",
        "        .content {{\n",
        "            padding: 30px;\n",
        "        }}\n",
        "        .flight-card {{\n",
        "            background: #f8f9fa;\n",
        "            border-radius: 10px;\n",
        "            padding: 25px;\n",
        "            margin: 20px 0;\n",
        "            border-left: 4px solid #667eea;\n",
        "        }}\n",
        "        .info-grid {{\n",
        "            display: grid;\n",
        "            grid-template-columns: 1fr 1fr;\n",
        "            gap: 15px;\n",
        "            margin: 20px 0;\n",
        "        }}\n",
        "        .info-item {{\n",
        "            background: white;\n",
        "            padding: 15px;\n",
        "            border-radius: 8px;\n",
        "            border: 1px solid #e9ecef;\n",
        "        }}\n",
        "        .badge {{\n",
        "            background: #667eea;\n",
        "            color: white;\n",
        "            padding: 5px 12px;\n",
        "            border-radius: 20px;\n",
        "            font-size: 12px;\n",
        "            font-weight: bold;\n",
        "        }}\n",
        "        .footer {{\n",
        "            background: #f8f9fa;\n",
        "            padding: 20px;\n",
        "            text-align: center;\n",
        "            color: #6c757d;\n",
        "            font-size: 12px;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <div class=\"header\">\n",
        "            <h1>‚úàÔ∏è Flight Confirmation</h1>\n",
        "            <p>Your journey is confirmed!</p>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"content\">\n",
        "            <h2>Hello {passenger}!</h2>\n",
        "            <p>Your flight details are confirmed and ready for your upcoming journey.</p>\n",
        "\n",
        "            <div class=\"flight-card\">\n",
        "                <h3>üõ´ Flight Itinerary</h3>\n",
        "                <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 20px 0;\">\n",
        "                    <div style=\"text-align: center;\">\n",
        "                        <div style=\"font-size: 24px; font-weight: bold;\">{departure}</div>\n",
        "                        <div style=\"color: #666;\">Departure</div>\n",
        "                    </div>\n",
        "                    <div style=\"font-size: 20px;\">‚Üí</div>\n",
        "                    <div style=\"text-align: center;\">\n",
        "                        <div style=\"font-size: 24px; font-weight: bold;\">{arrival}</div>\n",
        "                        <div style=\"color: #666;\">Arrival</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "\n",
        "                <div class=\"info-grid\">\n",
        "                    <div class=\"info-item\">\n",
        "                        <strong>üìÖ Date:</strong><br>{date}\n",
        "                    </div>\n",
        "                    <div class=\"info-item\">\n",
        "                        <strong>üïí Time:</strong><br>{time}\n",
        "                    </div>\n",
        "                    <div class=\"info-item\">\n",
        "                        <strong>üé´ Flight:</strong><br>{flight_num}\n",
        "                    </div>\n",
        "                    <div class=\"info-item\">\n",
        "                        <strong>üí∫ Seat:</strong><br>{seat}\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div style=\"background: #e8f5e8; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
        "                <h3>‚úÖ Booking Details</h3>\n",
        "                <p><strong>Booking Reference:</strong> <span class=\"badge\">{booking_ref}</span></p>\n",
        "                <p><strong>Class:</strong> <span class=\"badge\">{flight_class}</span></p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"footer\">\n",
        "            <p>Safe travels! ‚úàÔ∏è</p>\n",
        "            <p>This email was generated by your AI Flight Assistant</p>\n",
        "            <p>{datetime.now().strftime(\"%Y-%m-%d %H:%M\")}</p>\n",
        "        </div>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "    def send_flight_email(self, to_email: str, flight_data: Dict[str, Any], subject: str = None) -> str:\n",
        "        \"\"\"Send modern flight email with AI-generated template\"\"\"\n",
        "        try:\n",
        "            if not subject:\n",
        "                flight_num = flight_data.get('flight_number', 'Multiple Flights')\n",
        "                subject = f\"‚úàÔ∏è Flight Confirmation - {flight_num}\"\n",
        "\n",
        "            msg = MIMEMultipart('alternative')\n",
        "            msg['From'] = self.email\n",
        "            msg['To'] = to_email\n",
        "            msg['Subject'] = subject\n",
        "\n",
        "            # Generate modern HTML template\n",
        "            html_content = self.generate_modern_flight_email(flight_data)\n",
        "\n",
        "            # Create plain text version\n",
        "            text_content = f\"\"\"\n",
        "Flight Confirmation\n",
        "===================\n",
        "\n",
        "Passenger: {flight_data.get('passenger_name', 'N/A')}\n",
        "Flight: {flight_data.get('flight_number', 'N/A')}\n",
        "Route: {flight_data.get('departure_airport', 'N/A')} ‚Üí {flight_data.get('arrival_airport', 'N/A')}\n",
        "Date: {flight_data.get('departure_date', 'N/A')}\n",
        "Time: {flight_data.get('departure_time', 'N/A')}\n",
        "Seat: {flight_data.get('seat_number', 'N/A')}\n",
        "Class: {flight_data.get('class', 'N/A')}\n",
        "Booking Reference: {flight_data.get('booking_reference', 'N/A')}\n",
        "\n",
        "Safe travels!\n",
        "\"\"\"\n",
        "\n",
        "            part1 = MIMEText(text_content, 'plain')\n",
        "            part2 = MIMEText(html_content, 'html')\n",
        "\n",
        "            msg.attach(part1)\n",
        "            msg.attach(part2)\n",
        "\n",
        "            server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
        "            server.starttls()\n",
        "            server.login(self.email, self.password)\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "\n",
        "            return f\"‚úÖ Modern flight email sent successfully to {to_email}!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Failed to send email: {str(e)}\"\n",
        "\n",
        "    def send_conversation_history(self, to_email: str, conversation_history: List[str]) -> str:\n",
        "        \"\"\"Send conversation history via email\"\"\"\n",
        "        try:\n",
        "            msg = MIMEMultipart()\n",
        "            msg['From'] = self.email\n",
        "            msg['To'] = to_email\n",
        "            msg['Subject'] = \"Chat History from Flight Assistant\"\n",
        "\n",
        "            body = f\"Conversation History\\n{'='*50}\\n\\n\"\n",
        "            for entry in conversation_history:\n",
        "                body += f\"{entry}\\n\\n\"\n",
        "\n",
        "            msg.attach(MIMEText(body, 'plain'))\n",
        "            server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
        "            server.starttls()\n",
        "            server.login(self.email, self.password)\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "\n",
        "            return f\"‚úÖ Conversation history sent to {to_email}!\"\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Failed to send conversation history: {str(e)}\"\n",
        "\n",
        "# Enhanced RAG Document Processor\n",
        "class RAGDocumentProcessor:\n",
        "    def __init__(self, gemini_api_key: str):\n",
        "        self.gemini_api_key = gemini_api_key\n",
        "        self.uploaded_documents = {}\n",
        "        self.vector_store = None\n",
        "        self.embeddings = None\n",
        "        self.text_splitter = None\n",
        "        self.setup_components()\n",
        "\n",
        "    def setup_components(self):\n",
        "        \"\"\"Setup RAG components\"\"\"\n",
        "        try:\n",
        "            self.embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                model_kwargs={'device': 'cpu'}\n",
        "            )\n",
        "            self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=1000,\n",
        "                chunk_overlap=200,\n",
        "                length_function=len\n",
        "            )\n",
        "            self.llm = ChatGoogleGenerativeAI(\n",
        "                model=\"gemini-2.0-flash-exp\",\n",
        "                google_api_key=self.gemini_api_key,\n",
        "                temperature=0.3,\n",
        "                max_output_tokens=2048,\n",
        "                convert_system_message_to_human=True\n",
        "            )\n",
        "            print(\"‚úÖ RAG components initialized!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå RAG setup failed: {e}\")\n",
        "\n",
        "    def process_document(self, file_path: str) -> str:\n",
        "        \"\"\"Process document with RAG pipeline\"\"\"\n",
        "        try:\n",
        "            if file_path.endswith('.pdf'):\n",
        "                import PyPDF2\n",
        "                with open(file_path, 'rb') as file:\n",
        "                    pdf_reader = PyPDF2.PdfReader(file)\n",
        "                    text = \"\"\n",
        "                    for page in pdf_reader.pages:\n",
        "                        page_text = page.extract_text()\n",
        "                        if page_text:\n",
        "                            text += page_text + \"\\n\"\n",
        "            elif file_path.endswith('.txt'):\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    text = f.read()\n",
        "            else:\n",
        "                return \"‚ùå Unsupported file format\"\n",
        "\n",
        "            if not text or len(text.strip()) < 10:\n",
        "                return \"‚ùå No meaningful text extracted\"\n",
        "\n",
        "            filename = os.path.basename(file_path)\n",
        "            self.uploaded_documents[filename] = text\n",
        "            documents = self._create_document_chunks(text, filename)\n",
        "\n",
        "            if self.embeddings:\n",
        "                self.vector_store = FAISS.from_documents(documents, self.embeddings)\n",
        "                return f\"‚úÖ Document '{filename}' processed with RAG! ({len(text)} chars, {len(documents)} chunks)\"\n",
        "            else:\n",
        "                return f\"‚úÖ Document '{filename}' processed! ({len(text)} chars)\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Document processing error: {str(e)}\"\n",
        "\n",
        "    def _create_document_chunks(self, text: str, source: str) -> List[LangchainDocument]:\n",
        "        \"\"\"Split text into chunks for RAG\"\"\"\n",
        "        if self.text_splitter:\n",
        "            texts = self.text_splitter.split_text(text)\n",
        "            return [LangchainDocument(page_content=text, metadata={\"source\": source, \"chunk\": i})\n",
        "                   for i, text in enumerate(texts)]\n",
        "        else:\n",
        "            return [LangchainDocument(page_content=text, metadata={\"source\": source})]\n",
        "\n",
        "    def rag_search(self, query: str, k: int = 4) -> Tuple[str, List[str]]:\n",
        "        \"\"\"Search documents using RAG\"\"\"\n",
        "        if not self.vector_store:\n",
        "            return \"‚ùå No documents processed with RAG yet.\", []\n",
        "\n",
        "        try:\n",
        "            docs = self.vector_store.similarity_search(query, k=k)\n",
        "            context = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.page_content}\"\n",
        "                                 for i, doc in enumerate(docs)])\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Based on the document excerpts, answer the user's question.\n",
        "            If the information isn't in the documents, say so clearly.\n",
        "\n",
        "            DOCUMENT EXCERPTS:\n",
        "            {context}\n",
        "\n",
        "            USER QUESTION: {query}\n",
        "\n",
        "            ANSWER:\n",
        "            \"\"\"\n",
        "\n",
        "            if self.llm:\n",
        "                response = self.llm.invoke([HumanMessage(content=prompt)])\n",
        "                return response.content, [doc.page_content[:200] + \"...\" for doc in docs]\n",
        "            else:\n",
        "                return \"LLM not available for RAG search.\", []\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå RAG search error: {str(e)}\", []\n",
        "\n",
        "    def extract_flights_by_passenger(self, passenger_name: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Extract all flights for a specific passenger\"\"\"\n",
        "        if not self.vector_store:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            query = f\"flights for passenger {passenger_name}\"\n",
        "            docs = self.vector_store.similarity_search(query, k=10)\n",
        "            context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "            extraction_prompt = f\"\"\"\n",
        "            Extract ALL flight information for passenger {passenger_name}:\n",
        "\n",
        "            DOCUMENT CONTENT:\n",
        "            {context}\n",
        "\n",
        "            Extract all flights where passenger name is {passenger_name}.\n",
        "            Return as a list of flights with details.\n",
        "\n",
        "            FORMAT:\n",
        "            FLIGHT: [number]\n",
        "            FROM: [departure]\n",
        "            TO: [arrival]\n",
        "            DATE: [date]\n",
        "            TIME: [time]\n",
        "            SEAT: [seat]\n",
        "            CLASS: [class]\n",
        "            BOOKING: [reference]\n",
        "            ---\n",
        "            \"\"\"\n",
        "\n",
        "            if self.llm:\n",
        "                response = self.llm.invoke([HumanMessage(content=extraction_prompt)])\n",
        "                return self._parse_passenger_flights(response.content, passenger_name)\n",
        "            else:\n",
        "                return []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Passenger extraction failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _parse_passenger_flights(self, response: str, passenger_name: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Parse passenger flights from response\"\"\"\n",
        "        flights = []\n",
        "        current_flight = {}\n",
        "\n",
        "        lines = response.split('\\n')\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith('FLIGHT:'):\n",
        "                if current_flight:\n",
        "                    flights.append(current_flight)\n",
        "                current_flight = {'passenger_name': passenger_name}\n",
        "                current_flight['flight_number'] = line.split('FLIGHT:')[1].strip()\n",
        "            elif line.startswith('FROM:'):\n",
        "                current_flight['departure_airport'] = line.split('FROM:')[1].strip()\n",
        "            elif line.startswith('TO:'):\n",
        "                current_flight['arrival_airport'] = line.split('TO:')[1].strip()\n",
        "            elif line.startswith('DATE:'):\n",
        "                current_flight['departure_date'] = line.split('DATE:')[1].strip()\n",
        "            elif line.startswith('TIME:'):\n",
        "                current_flight['departure_time'] = line.split('TIME:')[1].strip()\n",
        "            elif line.startswith('SEAT:'):\n",
        "                current_flight['seat_number'] = line.split('SEAT:')[1].strip()\n",
        "            elif line.startswith('CLASS:'):\n",
        "                current_flight['class'] = line.split('CLASS:')[1].strip()\n",
        "            elif line.startswith('BOOKING:'):\n",
        "                current_flight['booking_reference'] = line.split('BOOKING:')[1].strip()\n",
        "\n",
        "        if current_flight:\n",
        "            flights.append(current_flight)\n",
        "\n",
        "        return flights\n",
        "\n",
        "    def extract_flights_by_city(self, city: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Extract all flights to/from a specific city\"\"\"\n",
        "        if not self.vector_store:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            query = f\"flights to {city} or from {city}\"\n",
        "            docs = self.vector_store.similarity_search(query, k=12)\n",
        "            context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "            extraction_prompt = f\"\"\"\n",
        "            Extract ALL flight information involving {city} (either departure or arrival):\n",
        "\n",
        "            DOCUMENT CONTENT:\n",
        "            {context}\n",
        "\n",
        "            Extract all flights where departure or arrival airport involves {city}.\n",
        "            Return as a list of flights with details.\n",
        "\n",
        "            FORMAT:\n",
        "            FLIGHT: [number]\n",
        "            PASSENGER: [name]\n",
        "            FROM: [departure]\n",
        "            TO: [arrival]\n",
        "            DATE: [date]\n",
        "            TIME: [time]\n",
        "            SEAT: [seat]\n",
        "            CLASS: [class]\n",
        "            BOOKING: [reference]\n",
        "            ---\n",
        "            \"\"\"\n",
        "\n",
        "            if self.llm:\n",
        "                response = self.llm.invoke([HumanMessage(content=extraction_prompt)])\n",
        "                return self._parse_city_flights(response.content, city)\n",
        "            else:\n",
        "                return []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå City extraction failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _parse_city_flights(self, response: str, city: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Parse city flights from response\"\"\"\n",
        "        flights = []\n",
        "        current_flight = {}\n",
        "\n",
        "        lines = response.split('\\n')\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith('FLIGHT:'):\n",
        "                if current_flight:\n",
        "                    flights.append(current_flight)\n",
        "                current_flight = {}\n",
        "                current_flight['flight_number'] = line.split('FLIGHT:')[1].strip()\n",
        "            elif line.startswith('PASSENGER:'):\n",
        "                current_flight['passenger_name'] = line.split('PASSENGER:')[1].strip()\n",
        "            elif line.startswith('FROM:'):\n",
        "                current_flight['departure_airport'] = line.split('FROM:')[1].strip()\n",
        "            elif line.startswith('TO:'):\n",
        "                current_flight['arrival_airport'] = line.split('TO:')[1].strip()\n",
        "            elif line.startswith('DATE:'):\n",
        "                current_flight['departure_date'] = line.split('DATE:')[1].strip()\n",
        "            elif line.startswith('TIME:'):\n",
        "                current_flight['departure_time'] = line.split('TIME:')[1].strip()\n",
        "            elif line.startswith('SEAT:'):\n",
        "                current_flight['seat_number'] = line.split('SEAT:')[1].strip()\n",
        "            elif line.startswith('CLASS:'):\n",
        "                current_flight['class'] = line.split('CLASS:')[1].strip()\n",
        "            elif line.startswith('BOOKING:'):\n",
        "                current_flight['booking_reference'] = line.split('BOOKING:')[1].strip()\n",
        "\n",
        "        if current_flight:\n",
        "            flights.append(current_flight)\n",
        "\n",
        "        return flights\n",
        "\n",
        "# Enhanced RAG Assistant with better email detection\n",
        "class RAGFlightAssistant:\n",
        "    def __init__(self, gemini_api_key: str, email_service: ModernEmailService):\n",
        "        self.gemini_api_key = gemini_api_key\n",
        "        self.email_service = email_service\n",
        "        self.document_processor = RAGDocumentProcessor(gemini_api_key)\n",
        "        self.conversation_history = []\n",
        "        self.setup_llm()\n",
        "\n",
        "    def setup_llm(self):\n",
        "        \"\"\"Setup LLM for general queries\"\"\"\n",
        "        try:\n",
        "            self.llm = ChatGoogleGenerativeAI(\n",
        "                model=\"gemini-2.0-flash-exp\",\n",
        "                google_api_key=self.gemini_api_key,\n",
        "                temperature=0.7,\n",
        "                max_output_tokens=2048,\n",
        "                convert_system_message_to_human=True\n",
        "            )\n",
        "            print(\"‚úÖ RAG Assistant LLM initialized!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Assistant LLM setup failed: {e}\")\n",
        "\n",
        "    def add_to_history(self, user_input: str, assistant_response: str):\n",
        "        \"\"\"Add conversation to history\"\"\"\n",
        "        self.conversation_history.append(f\"üë§ User: {user_input}\")\n",
        "        self.conversation_history.append(f\"ü§ñ Assistant: {assistant_response}\")\n",
        "        if len(self.conversation_history) > 40:\n",
        "            self.conversation_history = self.conversation_history[-40:]\n",
        "\n",
        "    def process_request(self, user_input: str) -> str:\n",
        "        \"\"\"Process user input with enhanced email capabilities\"\"\"\n",
        "        original_input = user_input\n",
        "\n",
        "        # Improved email detection with better pattern matching\n",
        "        email_pattern = r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+'\n",
        "        email_match = re.search(email_pattern, user_input)\n",
        "\n",
        "        # Check for email-related commands\n",
        "        has_email_command = any(keyword in user_input.lower() for keyword in\n",
        "                               ['send', 'email', 'mail', '@'])\n",
        "\n",
        "        # Check for passenger names\n",
        "        passenger_match = re.search(r'(Chris Brown|John Doe|Jane Smith|Bob Williams|Mary Jones|Alice Johnson|David Wilson)',\n",
        "                                  user_input, re.IGNORECASE)\n",
        "\n",
        "        # Check for city names\n",
        "        city_match = re.search(r'(new york|jfk|miami|london|paris|frankfurt|dubai|tokyo|sydney)',\n",
        "                             user_input.lower())\n",
        "\n",
        "        # Process email requests\n",
        "        if has_email_command and email_match:\n",
        "            email = email_match.group(0)\n",
        "\n",
        "            if passenger_match:\n",
        "                # Send flights for specific passenger\n",
        "                passenger_name = passenger_match.group(0)\n",
        "                flights = self.document_processor.extract_flights_by_passenger(passenger_name)\n",
        "\n",
        "                if flights:\n",
        "                    # Send first flight as example, or create summary\n",
        "                    result = self.email_service.send_flight_email(email, flights[0])\n",
        "                    return f\"‚úÖ {result}\\n\\nüìß Sent flight details for {passenger_name} to {email}\\n\\nFound {len(flights)} flights for {passenger_name}\"\n",
        "                else:\n",
        "                    return f\"‚ùå No flights found for passenger {passenger_name}\"\n",
        "\n",
        "            elif city_match:\n",
        "                # Send flights for specific city\n",
        "                city = city_match.group(0)\n",
        "                flights = self.document_processor.extract_flights_by_city(city)\n",
        "\n",
        "                if flights:\n",
        "                    # Create summary flight data\n",
        "                    summary_data = {\n",
        "                        'passenger_name': 'Multiple Passengers',\n",
        "                        'flight_number': f'{len(flights)} Flights',\n",
        "                        'departure_airport': 'Various',\n",
        "                        'arrival_airport': city.title(),\n",
        "                        'departure_date': 'Various',\n",
        "                        'departure_time': 'Various',\n",
        "                        'seat_number': 'Various',\n",
        "                        'class': 'Various',\n",
        "                        'booking_reference': 'Multiple',\n",
        "                        'flight_count': len(flights)\n",
        "                    }\n",
        "                    result = self.email_service.send_flight_email(email, summary_data)\n",
        "                    return f\"‚úÖ {result}\\n\\nüìß Sent {len(flights)} flights involving {city.title()} to {email}\"\n",
        "                else:\n",
        "                    return f\"‚ùå No flights found for {city.title()}\"\n",
        "\n",
        "            else:\n",
        "                # General email request\n",
        "                return f\"‚úÖ I can send flight details to {email}!\\n\\nPlease specify:\\n‚Ä¢ A passenger name (like Chris Brown)\\n‚Ä¢ Or a city (like New York)\\n\\nExample: 'Send Chris Brown flights to {email}'\"\n",
        "\n",
        "        # RAG search for other queries\n",
        "        elif self.document_processor.vector_store:\n",
        "            result, sources = self.document_processor.rag_search(user_input)\n",
        "            response = f\"üîç **Search Results:**\\n\\n{result}\"\n",
        "            if sources:\n",
        "                response += f\"\\n\\nüìö Based on document content\"\n",
        "            return response\n",
        "\n",
        "        else:\n",
        "            return \"üìù Please upload a document first using '/upload' command\"\n",
        "\n",
        "    def get_conversation_summary(self) -> str:\n",
        "        \"\"\"Get formatted conversation history\"\"\"\n",
        "        return \"\\n\".join(self.conversation_history[-10:])\n",
        "\n",
        "# File upload function\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    def files():\n",
        "        class DummyFiles:\n",
        "            def upload(self):\n",
        "                print(\"‚ö†Ô∏è File upload only available in Google Colab\")\n",
        "                return {}\n",
        "        return DummyFiles()\n",
        "\n",
        "def upload_file():\n",
        "    \"\"\"Handle file upload\"\"\"\n",
        "    try:\n",
        "        if IN_COLAB:\n",
        "            print(\"üì§ Please select your document (PDF/TXT)...\")\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                filename = list(uploaded.keys())[0]\n",
        "                print(f\"‚úÖ File '{filename}' uploaded successfully!\")\n",
        "                return filename\n",
        "            else:\n",
        "                print(\"‚ùå No file selected\")\n",
        "                return None\n",
        "        else:\n",
        "            # For non-Colab, create sample\n",
        "            sample_content = \"\"\"\n",
        "            FLIGHT CONFIRMATION\n",
        "            Booking Reference: ABC123\n",
        "            Passenger: John Smith\n",
        "            Flight: BA249\n",
        "            From: London Heathrow (LHR)\n",
        "            To: New York JFK (JFK)\n",
        "            Date: 2024-12-15\n",
        "            Time: 14:30\n",
        "            Seat: 15A\n",
        "            Class: Business\n",
        "            \"\"\"\n",
        "            with open(\"sample_flight.pdf\", \"w\") as f:\n",
        "                f.write(sample_content)\n",
        "            print(\"üìÑ Created sample flight document\")\n",
        "            return \"sample_flight.pdf\"\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Upload error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main application\n",
        "def main():\n",
        "    print(\"üöÄ **Enhanced RAG Flight Assistant with Email**\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize services\n",
        "    email_service = ModernEmailService(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
        "    assistant = RAGFlightAssistant(GEMINI_API_KEY, email_service)\n",
        "\n",
        "    print(\"\\nü§ñ **ENHANCED EMAIL FEATURES:**\")\n",
        "    print(\"\"\"\n",
        "‚úÖ **Smart Email Detection** - Automatically finds email addresses\n",
        "‚úÖ **Passenger-Specific Emails** - Send flights by passenger name\n",
        "‚úÖ **City-Specific Emails** - Send flights by city (New York, JFK, etc.)\n",
        "‚úÖ **Modern HTML Templates** - Beautiful, professional email designs\n",
        "\n",
        "**Try These Commands:**\n",
        "- 'send Chris Brown flights to emmanuelmakau53@gmail.com'\n",
        "- 'email all New York flights to myemail@gmail.com'\n",
        "- 'send flights to emmanuelmakau53@gmail.com for Chris Brown'\n",
        "- '/upload' - Process documents first\n",
        "- '/status' - Check system status\n",
        "    \"\"\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nüë§ You: \").strip()\n",
        "\n",
        "            if user_input.lower() in ['/quit', 'quit', 'exit']:\n",
        "                print(\"ü§ñ Thank you for using the enhanced flight assistant! ‚úàÔ∏è\")\n",
        "                break\n",
        "\n",
        "            elif user_input == '/upload':\n",
        "                filename = upload_file()\n",
        "                if filename:\n",
        "                    print(\"üîÑ Processing with RAG...\")\n",
        "                    result = assistant.document_processor.process_document(filename)\n",
        "                    print(f\"üìÑ {result}\")\n",
        "                continue\n",
        "\n",
        "            elif user_input == '/status':\n",
        "                status = \"üîç **System Status:**\\n\"\n",
        "                if assistant.document_processor.vector_store:\n",
        "                    docs = list(assistant.document_processor.uploaded_documents.keys())\n",
        "                    status += f\"‚úÖ RAG system active with {len(docs)} document(s)\\n\"\n",
        "                    status += f\"üìö Documents: {', '.join(docs)}\\n\"\n",
        "                    status += f\"üìß Email: Ready to send modern templates\\n\"\n",
        "                else:\n",
        "                    status += \"‚ùå No documents processed. Use '/upload'\\n\"\n",
        "                print(status)\n",
        "                continue\n",
        "\n",
        "            elif user_input == '/history':\n",
        "                history = assistant.get_conversation_summary()\n",
        "                if history:\n",
        "                    print(\"üìù **Recent Conversation:**\")\n",
        "                    print(history)\n",
        "                else:\n",
        "                    print(\"üí≠ No conversation history\")\n",
        "                continue\n",
        "\n",
        "            elif user_input == '/clear':\n",
        "                assistant.conversation_history = []\n",
        "                print(\"üßπ History cleared!\")\n",
        "                continue\n",
        "\n",
        "            elif not user_input:\n",
        "                continue\n",
        "\n",
        "            # Process input\n",
        "            print(\"ü§ñ Assistant: \", end=\"\")\n",
        "            response = assistant.process_request(user_input)\n",
        "            print(response)\n",
        "\n",
        "            # Add to history\n",
        "            assistant.add_to_history(user_input, response)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nüõë Session ended\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Fdc2ktHwPMEL",
        "outputId": "689fd968-cecc-4d9a-feca-a9504bd7c57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All LangChain imports successful!\n",
            "üöÄ **Enhanced RAG Flight Assistant with Email**\n",
            "============================================================\n",
            "‚úÖ RAG components initialized!\n",
            "‚úÖ RAG Assistant LLM initialized!\n",
            "\n",
            "ü§ñ **ENHANCED EMAIL FEATURES:**\n",
            "\n",
            "‚úÖ **Smart Email Detection** - Automatically finds email addresses\n",
            "‚úÖ **Passenger-Specific Emails** - Send flights by passenger name\n",
            "‚úÖ **City-Specific Emails** - Send flights by city (New York, JFK, etc.)\n",
            "‚úÖ **Modern HTML Templates** - Beautiful, professional email designs\n",
            "\n",
            "**Try These Commands:**\n",
            "- 'send Chris Brown flights to emmanuelmakau53@gmail.com'\n",
            "- 'email all New York flights to myemail@gmail.com'  \n",
            "- 'send flights to emmanuelmakau53@gmail.com for Chris Brown'\n",
            "- '/upload' - Process documents first\n",
            "- '/status' - Check system status\n",
            "    \n",
            "============================================================\n",
            "\n",
            "üë§ You: /upload\n",
            "üì§ Please select your document (PDF/TXT)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3e86c463-8ef9-4973-bdd8-b7b44cb72043\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3e86c463-8ef9-4973-bdd8-b7b44cb72043\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_flight_info.pdf to sample_flight_info (4).pdf\n",
            "‚úÖ File 'sample_flight_info (4).pdf' uploaded successfully!\n",
            "üîÑ Processing with RAG...\n",
            "üìÑ ‚úÖ Document 'sample_flight_info (4).pdf' processed with RAG! (8247 chars, 11 chunks)\n",
            "\n",
            "üë§ You: send flights to emmanuelmakau53@gmail.com for Chris Brown\n",
            "ü§ñ Assistant: ‚úÖ ‚úÖ Modern flight email sent successfully to emmanuelmakau53@gmail.com!\n",
            "\n",
            "üìß Sent flight details for Chris Brown to emmanuelmakau53@gmail.com\n",
            "\n",
            "Found 14 flights for Chris Brown\n",
            "\n",
            "üë§ You: modernise it and make it at allmodernising email tempmlete\n",
            "ü§ñ Assistant: üîç **Search Results:**\n",
            "\n",
            "I am sorry, but I cannot fulfill that request. There is no information about email templates in the provided documents.\n",
            "\n",
            "\n",
            "üìö Based on document content\n",
            "\n",
            "üë§ You: give me all thoseflights please\n",
            "ü§ñ Assistant: üîç **Search Results:**\n",
            "\n",
            "Please specify the criteria for \"those flights\". For example, are you looking for flights for a specific person, between certain cities, or on a particular date? Once you provide more details, I can search the documents and provide a relevant list of flights.\n",
            "\n",
            "\n",
            "üìö Based on document content\n",
            "\n",
            "üë§ You: flights to newyork \n",
            "ü§ñ Assistant: üîç **Search Results:**\n",
            "\n",
            "Here's a list of flights to New York (JFK) from the provided documents:\n",
            "\n",
            "*   **G2257:** CDG to JFK, 2025-02-12, Arr 2025-02-13, Passenger: Bob Williams\n",
            "*   **U9685:** DXB to JFK, 2025-11-05, Passenger: John Doe\n",
            "*   **L5275:** DXB to JFK, 2025-03-24, Passenger: Chris Brown\n",
            "*   **G6970:** SIN to JFK, 2025-11-05, Passenger: Jane Smith\n",
            "*   **A8209:** FRA to JFK, 2025-05-16, Passenger: Jane Smith\n",
            "*   **F5687:** LAX to JFK, 2025-06-25, Passenger: Chris Brown\n",
            "*   **N4618:** JFK to CDG, 2025-02-27, Passenger: Jane Smith\n",
            "*   **U5538:** CDG to JFK, 2025-11-15, Passenger: Mary Jones\n",
            "\n",
            "\n",
            "üìö Based on document content\n",
            "\n",
            "üë§ You: yeah then send this to email G6970  to this email emmanuelmakau53@gmail.com\n",
            "ü§ñ Assistant: ‚úÖ I can send flight details to emmanuelmakau53@gmail.com!\n",
            "\n",
            "Please specify:\n",
            "‚Ä¢ A passenger name (like Chris Brown)\n",
            "‚Ä¢ Or a city (like New York)\n",
            "\n",
            "Example: 'Send Chris Brown flights to emmanuelmakau53@gmail.com'\n",
            "\n",
            "üë§ You: chris Brown\n",
            "ü§ñ Assistant: üîç **Search Results:**\n",
            "\n",
            "The provided documents contain the following information about Chris Brown:\n",
            "\n",
            "*   **BR52977:** 27F, Business class, FRA to NBO, 2025-09-19 (Departure: 05:38, Arrival: 17:38)\n",
            "*   **BR37147:** 23U, First class, LHR to LAX, 2025-07-28 (Departure: 19:30, Arrival: 22:30)\n",
            "*   **BR34391:** 21T, Economy class, FRA to JFK, 2025-02-05 (Departure: 13:19, Arrival: 2025-02-06 02:19)\n",
            "*   **BR50134:** 2B, First class\n",
            "*   **BR24493:** 12L, Business class, DXB to JFK, 2025-05-01 (Departure: 03:32, Arrival: 11:32)\n",
            "*   **BR65564:** 29B, First class, CDG to SIN, 2025-07-28 (Departure: 09:16, Arrival: 13:16)\n",
            "*   **BR83756:** 2V, First class, LAX to SIN, 2025-09-04 (Departure: 10:19, Arrival: 13:19)\n",
            "*   **BR80619:** 40U, Business class, AMS to SIN, 2025-05-31 (Departure: 16:50, Arrival: 2025-06-01 07:50)\n",
            "*   **BR10107:** 11U, Economy class, DXB to SIN, 2025-07-27 (Departure: 14:25, Arrival: 15:25)\n",
            "\n",
            "üìö Based on document content\n",
            "\n",
            "üë§ You: give me send the details to that email\n",
            "ü§ñ Assistant: üîç **Search Results:**\n",
            "\n",
            "I am sorry, I cannot fulfill that request. I cannot send emails.\n",
            "\n",
            "\n",
            "üìö Based on document content\n",
            "\n",
            "üë§ You: - 'send Chris Brown flights to emmanuelmakau53@gmail.com'\n",
            "ü§ñ Assistant: ‚úÖ ‚úÖ Modern flight email sent successfully to emmanuelmakau53@gmail.com!\n",
            "\n",
            "üìß Sent flight details for Chris Brown to emmanuelmakau53@gmail.com\n",
            "\n",
            "Found 14 flights for Chris Brown\n",
            "\n",
            "üë§ You: and any other flight related from him\n",
            "ü§ñ Assistant: üîç **Search Results:**\n",
            "\n",
            "I cannot answer this question. The provided document excerpts do not contain information about \"any other flight related from him\".\n",
            "\n",
            "\n",
            "üìö Based on document content\n"
          ]
        }
      ]
    }
  ]
}