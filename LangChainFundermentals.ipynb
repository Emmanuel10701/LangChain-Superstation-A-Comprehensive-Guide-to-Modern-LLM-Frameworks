{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa/r5Bi12OzQz62ZMHCCsw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emmanuel10701/LangChain-Superstation-A-Comprehensive-Guide-to-Modern-LLM-Frameworks/blob/main/LangChainFundermentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "tjZWXCHSf881",
        "outputId": "7209a19d-4434-4658-9f03-a2de4b9bf61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Welcome to the Advanced AI Assistant!\n",
            "I can help with various tasks, answer questions, search the web, and more.\n",
            "Type 'quit' or 'exit' to end the conversation.\n",
            "\n",
            "You: hello\n",
            "AI: Hello! I'm your AI assistant. How can I help you today?\n",
            "\n",
            "You: what is my name\n",
            "AI: I do not know your name.  I have no access to personal information unless you explicitly provide it to me.  What would you like me to call you?\n",
            "\n",
            "You: my nameis juma\n",
            "AI: It's nice to meet you, Juma!  How can I help you today?\n",
            "\n",
            "You: what is my name\n",
            "AI: Your name is Juma.\n",
            "\n",
            "You: yeah greate\n",
            "AI: Great! Is there anything I can help you with today, Juma?\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2101979131.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;31m# Run the chat interface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mchat_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2101979131.py\u001b[0m in \u001b[0;36mchat_interface\u001b[0;34m()\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -qU langchain langchain-community langchain-google-genai langgraph faiss-cpu tiktoken wikipedia google-api-python-client\n",
        "\n",
        "# Import required modules\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import TypedDict, List, Optional, Annotated, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "import operator\n",
        "from enum import Enum\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_community.tools import WikipediaQueryRun # Removed DuckDuckGoSearchRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_core.tools import Tool # Import Tool class\n",
        "# from langgraph.checkpoint.sqlite import SqliteSaver # Removed SqliteSaver import\n",
        "import getpass\n",
        "\n",
        "# Set up API keys\n",
        "# try:\n",
        "# Use getpass to securely prompt for the API key\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI Studio API key: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBj4DPP_wKEWqTyl4rWHOlkhc7wAgSeeD4\" # Hardcoded API key as requested\n",
        "# except Exception as e:\n",
        "#     print(f\"Error setting Google API key: {e}. Some features may not work.\")\n",
        "\n",
        "# Removed OpenAI API key setup\n",
        "# try:\n",
        "#     # Use getpass to securely prompt for the API key\n",
        "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error setting OpenAI API key: {e}. Some features may not work.\")\n",
        "\n",
        "\n",
        "# Initialize LLM with streaming enabled\n",
        "llm_gemini = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash-latest\",\n",
        "    temperature=0.7,\n",
        "    disable_streaming=False # Changed streaming=True to disable_streaming=False\n",
        ")\n",
        "\n",
        "# Removed OpenAI LLM initialization\n",
        "# llm_openai = ChatOpenAI(\n",
        "#     model=\"gpt-4-turbo-preview\",\n",
        "#     temperature=0.7,\n",
        "#     streaming=True\n",
        "# )\n",
        "\n",
        "\n",
        "# Use Gemini for embeddings\n",
        "try:\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Google Embeddings: {e}. Embeddings will not be available.\")\n",
        "    embeddings = None\n",
        "\n",
        "# Removed OpenAI Embeddings initialization\n",
        "# try:\n",
        "#     embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error initializing Google Embeddings: {e}. Falling back to OpenAI Embeddings.\")\n",
        "#     try:\n",
        "#         embeddings = OpenAIEmbeddings()\n",
        "#     except Exception as openai_e:\n",
        "#         print(f\"Error initializing OpenAI Embeddings: {openai_e}. Embeddings will not be available.\")\n",
        "#         embeddings = None\n",
        "\n",
        "\n",
        "# Define the agent state\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    current_topic: str\n",
        "    conversation_history: List[dict]\n",
        "    user_profile: dict\n",
        "    knowledge_base: Optional[str]\n",
        "    needs_clarification: bool\n",
        "    clarification_question: Optional[str]\n",
        "\n",
        "# Define tools for the agent\n",
        "# Web search tool - Removed DuckDuckGoSearchRun\n",
        "# search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Wikipedia tool\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "\n",
        "# Custom tools - Wrapped in Tool objects\n",
        "def get_current_time_func():\n",
        "    \"\"\"Returns the current date and time.\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "get_current_time = Tool(\n",
        "    name=\"get_current_time\",\n",
        "    description=\"Returns the current date and time.\",\n",
        "    func=get_current_time_func\n",
        ")\n",
        "\n",
        "def save_conversation_to_file_func(filename: str = None):\n",
        "    \"\"\"Saves the conversation to a file.\"\"\"\n",
        "    # This function needs access to the state to save the messages.\n",
        "    # It's better to handle this within a node or pass state explicitly.\n",
        "    # For now, returning a placeholder message.\n",
        "    return \"Save conversation tool needs state access. Functionality not fully implemented here.\"\n",
        "\n",
        "save_conversation_to_file = Tool(\n",
        "    name=\"save_conversation_to_file\",\n",
        "    description=\"Saves the conversation to a file. Accepts an optional filename.\",\n",
        "    func=save_conversation_to_file_func # Note: This function needs state access to work fully\n",
        ")\n",
        "\n",
        "\n",
        "def load_knowledge_base_func(url: str, state: AgentState):\n",
        "    \"\"\"Loads content from a URL into the knowledge base.\"\"\"\n",
        "    if embeddings is None:\n",
        "        return \"Embeddings not initialized. Cannot load knowledge base.\"\n",
        "    try:\n",
        "        loader = WebBaseLoader(url)\n",
        "        documents = loader.load()\n",
        "\n",
        "        # Split documents into chunks\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "        docs = text_splitter.split_documents(documents)\n",
        "\n",
        "        # Create vectorstore\n",
        "        vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "        state[\"knowledge_base\"] = vectorstore.as_retriever()\n",
        "\n",
        "        return f\"Knowledge base loaded from {url} with {len(docs)} chunks\"\n",
        "    except Exception as e:\n",
        "        return f\"Error loading knowledge base: {str(e)}\"\n",
        "\n",
        "# Load knowledge base tool - requires state access\n",
        "# Will need to handle how state is passed to this tool in the graph\n",
        "load_knowledge_base_tool = Tool(\n",
        "    name=\"load_knowledge_base\",\n",
        "    description=\"Loads content from a URL into the knowledge base. Accepts a URL.\",\n",
        "    func=lambda url: \"Load knowledge base tool needs state access. Functionality not fully implemented here.\", # Placeholder for now\n",
        ")\n",
        "\n",
        "\n",
        "def query_knowledge_base_func(query: str, state: AgentState):\n",
        "    \"\"\"Queries the loaded knowledge base.\"\"\"\n",
        "    if not state.get(\"knowledge_base\"):\n",
        "        return \"No knowledge base loaded. Please load a knowledge base first.\"\n",
        "\n",
        "    if embeddings is None:\n",
        "         return \"Embeddings not initialized. Cannot query knowledge base.\"\n",
        "\n",
        "    try:\n",
        "        results = state[\"knowledge_base\"].get_relevant_documents(query)\n",
        "        if results:\n",
        "            return \"\\n\\n\".join([f\"Source: {doc.metadata.get('source', 'Unknown')}\\nContent: {doc.page_content}\"\n",
        "                              for doc in results[:3]])\n",
        "        else:\n",
        "            return \"No relevant information found in the knowledge base.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error querying knowledge base: {str(e)}\"\n",
        "\n",
        "# Query knowledge base tool - requires state access\n",
        "# Will need to handle how state is passed to this tool in the graph\n",
        "query_knowledge_base_tool = Tool(\n",
        "    name=\"query_knowledge_base\",\n",
        "    description=\"Queries the loaded knowledge base. Accepts a query string.\",\n",
        "    func=lambda query: \"Query knowledge base tool needs state access. Functionality not fully implemented here.\", # Placeholder for now\n",
        ")\n",
        "\n",
        "\n",
        "# Create tool list\n",
        "tools = [\n",
        "    # search, # Removed search tool\n",
        "    wikipedia,\n",
        "    get_current_time,\n",
        "    # save_conversation_to_file, # Temporarily removed due to state dependency\n",
        "    # load_knowledge_base_tool, # Temporarily removed due to state dependency\n",
        "    # query_knowledge_base_tool # Temporarily removed due to state dependency\n",
        "]\n",
        "\n",
        "# Create the agent with memory and tools\n",
        "def create_agent():\n",
        "    # System prompt with instructions\n",
        "    system_prompt = \"\"\"You are a helpful, versatile AI assistant. You have access to various tools and a memory of the conversation.\n",
        "\n",
        "Guidelines:\n",
        "1. Be helpful, friendly, and engaging\n",
        "2. Use the available tools when appropriate\n",
        "3. Maintain context from the conversation history\n",
        "4. Ask clarifying questions when needed\n",
        "5. Adapt your response style based on the conversation topic\n",
        "6. Use the knowledge base if available and relevant\n",
        "\n",
        "Available tools:\n",
        "- Wikipedia: For encyclopedic knowledge\n",
        "- Get current time: To check the time\n",
        "# - Save conversation: To save the chat to a file # Removed tool description\n",
        "# - Load knowledge base: To load information from a URL # Removed tool description\n",
        "# - Query knowledge base: To search through loaded information # Removed tool description\n",
        "\n",
        "Always think step by step and use tools when they can provide better information.\"\"\"\n",
        "\n",
        "    # Prompt template\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "    ])\n",
        "\n",
        "    # Create the agent using Gemini as the primary LLM\n",
        "    agent = create_tool_calling_agent(llm_gemini, tools, prompt)\n",
        "    return AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "# Initialize the agent\n",
        "agent_executor = create_agent()\n",
        "\n",
        "# Define the graph workflow\n",
        "def route_conversation(state: AgentState):\n",
        "    \"\"\"Routes the conversation based on the last message.\"\"\"\n",
        "    last_message = state[\"messages\"][-1].content.lower()\n",
        "\n",
        "    # Check if this is a greeting\n",
        "    if any(word in last_message for word in [\"hello\", \"hi\", \"hey\", \"greetings\"]):\n",
        "        return \"greeting_response\"\n",
        "\n",
        "    # Check if this requires a tool\n",
        "    if any(keyword in last_message for keyword in [\"search for\", \"look up\", \"wikipedia\", \"current time\", \"save conversation\", \"load\", \"knowledge base\"]):\n",
        "        # Note: \"search for\" might no longer be routed to a tool if DuckDuckGo is removed,\n",
        "        # but Wikipedia still handles \"look up\" and \"wikipedia\".\n",
        "        # Also removed keywords for tools that require state access\n",
        "        if any(keyword in last_message for keyword in [\"save conversation\", \"load\", \"knowledge base\"]):\n",
        "            return \"general_response\" # Route state-dependent tool calls to general response for now\n",
        "\n",
        "        return \"use_tool\"\n",
        "\n",
        "    # Check if this needs clarification\n",
        "    if state.get(\"needs_clarification\", False):\n",
        "        return \"ask_clarification\"\n",
        "\n",
        "    # Default to general response\n",
        "    return \"general_response\"\n",
        "\n",
        "# Define node functions\n",
        "def greeting_response(state: AgentState):\n",
        "    \"\"\"Generates a greeting response.\"\"\"\n",
        "    response = \"Hello! I'm your AI assistant. How can I help you today?\"\n",
        "    state[\"messages\"].append(AIMessage(content=response))\n",
        "    return state\n",
        "\n",
        "def use_tool(state: AgentState):\n",
        "    \"\"\"Uses tools to respond to the user.\"\"\"\n",
        "    try:\n",
        "        # Get the last human message\n",
        "        input_text = state[\"messages\"][-1].content\n",
        "\n",
        "        # Run the agent with tools\n",
        "        result = agent_executor.invoke({\"input\": input_text, \"messages\": state[\"messages\"]})\n",
        "\n",
        "        # Add the response to the messages\n",
        "        state[\"messages\"].append(AIMessage(content=result[\"output\"]))\n",
        "\n",
        "        # Update conversation topic if needed\n",
        "        if not state.get(\"current_topic\"):\n",
        "            state[\"current_topic\"] = \"general inquiry\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"I encountered an error: {str(e)}. Please try again.\"\n",
        "        state[\"messages\"].append(AIMessage(content=error_msg))\n",
        "\n",
        "    return state\n",
        "\n",
        "def ask_clarification(state: AgentState):\n",
        "    \"\"\"Asks for clarification when needed.\"\"\"\n",
        "    clarification_question = state.get(\"clarification_question\", \"Could you please clarify what you mean?\")\n",
        "    state[\"messages\"].append(AIMessage(content=clarification_question))\n",
        "    state[\"needs_clarification\"] = False\n",
        "    state[\"clarification_question\"] = None\n",
        "    return state\n",
        "\n",
        "def general_response(state: AgentState):\n",
        "    \"\"\"Generates a general response using the LLM.\"\"\"\n",
        "    try:\n",
        "        # Use the LLM to generate a response\n",
        "        messages = state[\"messages\"]\n",
        "\n",
        "        # Create a prompt for the LLM\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"You are a helpful AI assistant. Continue the conversation naturally based on the history.\"),\n",
        "            MessagesPlaceholder(variable_name=\"messages\")\n",
        "        ])\n",
        "\n",
        "        # Use Gemini for general responses\n",
        "        chain = prompt | llm_gemini | StrOutputParser()\n",
        "        response = chain.invoke({\"messages\": messages})\n",
        "\n",
        "        # Add to messages\n",
        "        state[\"messages\"].append(AIMessage(content=response))\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"I encountered an error: {str(e)}. Please try again.\"\n",
        "        state[\"messages\"].append(AIMessage(content=error_msg))\n",
        "\n",
        "    return state\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"greeting_response\", greeting_response)\n",
        "workflow.add_node(\"use_tool\", use_tool)\n",
        "workflow.add_node(\"ask_clarification\", ask_clarification)\n",
        "workflow.add_node(\"general_response\", general_response)\n",
        "\n",
        "# Add edges\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_conversation,\n",
        "    {\n",
        "        \"greeting_response\": \"greeting_response\",\n",
        "        \"use_tool\": \"use_tool\",\n",
        "        \"ask_clarification\": \"ask_clarification\",\n",
        "        \"general_response\": \"general_response\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"greeting_response\", END)\n",
        "workflow.add_edge(\"use_tool\", END)\n",
        "workflow.add_edge(\"ask_clarification\", END)\n",
        "workflow.add_edge(\"general_response\", END) # Changed to add_edge\n",
        "\n",
        "\n",
        "# Compile the graph\n",
        "# memory = SqliteSaver.from_conn_string(\":memory:\") # Removed SqliteSaver initialization\n",
        "app = workflow.compile() # Removed checkpointer argument\n",
        "\n",
        "# Chat interface\n",
        "def chat_interface():\n",
        "    print(\" Welcome to the Advanced AI Assistant!\")\n",
        "    print(\"I can help with various tasks, answer questions, search the web, and more.\")\n",
        "    print(\"Type 'quit' or 'exit' to end the conversation.\\n\")\n",
        "\n",
        "    # Initialize conversation\n",
        "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "    state = {\n",
        "        \"messages\": [],\n",
        "        \"current_topic\": \"\",\n",
        "        \"conversation_history\": [],\n",
        "        \"user_profile\": {},\n",
        "        \"knowledge_base\": None,\n",
        "        \"needs_clarification\": False,\n",
        "        \"clarification_question\": None\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "            print(\"AI: Goodbye! It was nice chatting with you.\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        # Add user message to state\n",
        "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
        "\n",
        "        # Invoke the graph\n",
        "        try:\n",
        "            # Pass the config to the invoke call\n",
        "            result = app.invoke(state, config)\n",
        "            state = result\n",
        "\n",
        "            # Print the last AI response\n",
        "            if state[\"messages\"] and isinstance(state[\"messages\"][-1], AIMessage):\n",
        "                print(f\"AI: {state['messages'][-1].content}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"AI: I encountered an error: {str(e)}. Please try again.\")\n",
        "\n",
        "        print()  # Empty line for readability\n",
        "\n",
        "# Run the chat interface\n",
        "if __name__ == \"__main__\":\n",
        "    chat_interface()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xGj9bwUto5tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d65199c3"
      },
      "source": [
        "# Task\n",
        "Integrate Wikipedia and YouTube APIs for real news search into the existing agent code, adding comments to the new sections, and manually replace the existing API key with \"AIzaSyBj4DPP_wKEWqTyl4rWHOlkhc7wAgSeeD4\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "473ec783"
      },
      "source": [
        "## Install libraries\n",
        "\n",
        "### Subtask:\n",
        "Add necessary libraries for interacting with the YouTube API to the `pip install` command.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f5bc6da"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to add the `google-api-python-client` library to the `pip install` command in the first code cell. I will edit the cell to include this library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "39016933",
        "outputId": "1f66831b-4b2b-4e9b-85af-87f1e657f3fa"
      },
      "source": [
        "# Install necessary libraries\n",
        "!pip install -qU langchain langchain-community langchain-google-genai langgraph faiss-cpu tiktoken wikipedia google-api-python-client\n",
        "\n",
        "# Import required modules\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import TypedDict, List, Optional, Annotated, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "import operator\n",
        "from enum import Enum\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_community.tools import WikipediaQueryRun # Removed DuckDuckGoSearchRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_core.tools import Tool # Import Tool class\n",
        "# from langgraph.checkpoint.sqlite import SqliteSaver # Removed SqliteSaver import\n",
        "import getpass\n",
        "\n",
        "# Set up API keys\n",
        "# try:\n",
        "# Use getpass to securely prompt for the API key\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI Studio API key: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBj4DPP_wKEWqTyl4rWHOlkhc7wAgSeeD4\" # Hardcoded API key as requested\n",
        "# except Exception as e:\n",
        "#     print(f\"Error setting Google API key: {e}. Some features may not work.\")\n",
        "\n",
        "# Removed OpenAI API key setup\n",
        "# try:\n",
        "#     # Use getpass to securely prompt for the API key\n",
        "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error setting OpenAI API key: {e}. Some features may not work.\")\n",
        "\n",
        "\n",
        "# Initialize LLM with streaming enabled\n",
        "llm_gemini = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash-latest\",\n",
        "    temperature=0.7,\n",
        "    disable_streaming=False # Changed streaming=True to disable_streaming=False\n",
        ")\n",
        "\n",
        "# Removed OpenAI LLM initialization\n",
        "# llm_openai = ChatOpenAI(\n",
        "#     model=\"gpt-4-turbo-preview\",\n",
        "#     temperature=0.7,\n",
        "#     streaming=True\n",
        "# )\n",
        "\n",
        "\n",
        "# Use Gemini for embeddings\n",
        "try:\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Google Embeddings: {e}. Embeddings will not be available.\")\n",
        "    embeddings = None\n",
        "\n",
        "# Removed OpenAI Embeddings initialization\n",
        "# try:\n",
        "#     embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error initializing Google Embeddings: {e}. Falling back to OpenAI Embeddings.\")\n",
        "#     try:\n",
        "#         embeddings = OpenAIEmbeddings()\n",
        "#     except Exception as openai_e:\n",
        "#         print(f\"Error initializing OpenAI Embeddings: {openai_e}. Embeddings will not be available.\")\n",
        "#         embeddings = None\n",
        "\n",
        "\n",
        "# Define the agent state\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    current_topic: str\n",
        "    conversation_history: List[dict]\n",
        "    user_profile: dict\n",
        "    knowledge_base: Optional[str]\n",
        "    needs_clarification: bool\n",
        "    clarification_question: Optional[str]\n",
        "\n",
        "# Define tools for the agent\n",
        "# Web search tool - Removed DuckDuckGoSearchRun\n",
        "# search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Wikipedia tool\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "\n",
        "# Custom tools - Wrapped in Tool objects\n",
        "def get_current_time_func():\n",
        "    \"\"\"Returns the current date and time.\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "get_current_time = Tool(\n",
        "    name=\"get_current_time\",\n",
        "    description=\"Returns the current date and time.\",\n",
        "    func=get_current_time_func\n",
        ")\n",
        "\n",
        "def save_conversation_to_file_func(filename: str = None):\n",
        "    \"\"\"Saves the conversation to a file.\"\"\"\n",
        "    # This function needs access to the state to save the messages.\n",
        "    # It's better to handle this within a node or pass state explicitly.\n",
        "    # For now, returning a placeholder message.\n",
        "    return \"Save conversation tool needs state access. Functionality not fully implemented here.\"\n",
        "\n",
        "save_conversation_to_file = Tool(\n",
        "    name=\"save_conversation_to_file\",\n",
        "    description=\"Saves the conversation to a file. Accepts an optional filename.\",\n",
        "    func=save_conversation_to_file_func # Note: This function needs state access to work fully\n",
        ")\n",
        "\n",
        "\n",
        "def load_knowledge_base_func(url: str, state: AgentState):\n",
        "    \"\"\"Loads content from a URL into the knowledge base.\"\"\"\n",
        "    if embeddings is None:\n",
        "        return \"Embeddings not initialized. Cannot load knowledge base.\"\n",
        "    try:\n",
        "        loader = WebBaseLoader(url)\n",
        "        documents = loader.load()\n",
        "\n",
        "        # Split documents into chunks\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "        docs = text_splitter.split_documents(documents)\n",
        "\n",
        "        # Create vectorstore\n",
        "        vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "        state[\"knowledge_base\"] = vectorstore.as_retriever()\n",
        "\n",
        "        return f\"Knowledge base loaded from {url} with {len(docs)} chunks\"\n",
        "    except Exception as e:\n",
        "        return f\"Error loading knowledge base: {str(e)}\"\n",
        "\n",
        "# Load knowledge base tool - requires state access\n",
        "# Will need to handle how state is passed to this tool in the graph\n",
        "load_knowledge_base_tool = Tool(\n",
        "    name=\"load_knowledge_base\",\n",
        "    description=\"Loads content from a URL into the knowledge base. Accepts a URL.\",\n",
        "    func=lambda url: \"Load knowledge base tool needs state access. Functionality not fully implemented here.\", # Placeholder for now\n",
        ")\n",
        "\n",
        "\n",
        "def query_knowledge_base_func(query: str, state: AgentState):\n",
        "    \"\"\"Queries the loaded knowledge base.\"\"\"\n",
        "    if not state.get(\"knowledge_base\"):\n",
        "        return \"No knowledge base loaded. Please load a knowledge base first.\"\n",
        "\n",
        "    if embeddings is None:\n",
        "         return \"Embeddings not initialized. Cannot query knowledge base.\"\n",
        "\n",
        "    try:\n",
        "        results = state[\"knowledge_base\"].get_relevant_documents(query)\n",
        "        if results:\n",
        "            return \"\\n\\n\".join([f\"Source: {doc.metadata.get('source', 'Unknown')}\\nContent: {doc.page_content}\"\n",
        "                              for doc in results[:3]])\n",
        "        else:\n",
        "            return \"No relevant information found in the knowledge base.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error querying knowledge base: {str(e)}\"\n",
        "\n",
        "# Query knowledge base tool - requires state access\n",
        "# Will need to handle how state is passed to this tool in the graph\n",
        "query_knowledge_base_tool = Tool(\n",
        "    name=\"query_knowledge_base\",\n",
        "    description=\"Queries the loaded knowledge base. Accepts a query string.\",\n",
        "    func=lambda query: \"Query knowledge base tool needs state access. Functionality not fully implemented here.\", # Placeholder for now\n",
        ")\n",
        "\n",
        "\n",
        "# Create tool list\n",
        "tools = [\n",
        "    # search, # Removed search tool\n",
        "    wikipedia,\n",
        "    get_current_time,\n",
        "    # save_conversation_to_file, # Temporarily removed due to state dependency\n",
        "    # load_knowledge_base_tool, # Temporarily removed due to state dependency\n",
        "    # query_knowledge_base_tool # Temporarily removed due to state dependency\n",
        "]\n",
        "\n",
        "# Create the agent with memory and tools\n",
        "def create_agent():\n",
        "    # System prompt with instructions\n",
        "    system_prompt = \"\"\"You are a helpful, versatile AI assistant. You have access to various tools and a memory of the conversation.\n",
        "\n",
        "Guidelines:\n",
        "1. Be helpful, friendly, and engaging\n",
        "2. Use the available tools when appropriate\n",
        "3. Maintain context from the conversation history\n",
        "4. Ask clarifying questions when needed\n",
        "5. Adapt your response style based on the conversation topic\n",
        "6. Use the knowledge base if available and relevant\n",
        "\n",
        "Available tools:\n",
        "- Wikipedia: For encyclopedic knowledge\n",
        "- Get current time: To check the time\n",
        "# - Save conversation: To save the chat to a file # Removed tool description\n",
        "# - Load knowledge base: To load information from a URL # Removed tool description\n",
        "# - Query knowledge base: To search through loaded information # Removed tool description\n",
        "\n",
        "Always think step by step and use tools when they can provide better information.\"\"\"\n",
        "\n",
        "    # Prompt template\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "    ])\n",
        "\n",
        "    # Create the agent using Gemini as the primary LLM\n",
        "    agent = create_tool_calling_agent(llm_gemini, tools, prompt)\n",
        "    return AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "# Initialize the agent\n",
        "agent_executor = create_agent()\n",
        "\n",
        "# Define the graph workflow\n",
        "def route_conversation(state: AgentState):\n",
        "    \"\"\"Routes the conversation based on the last message.\"\"\"\n",
        "    last_message = state[\"messages\"][-1].content.lower()\n",
        "\n",
        "    # Check if this is a greeting\n",
        "    if any(word in last_message for word in [\"hello\", \"hi\", \"hey\", \"greetings\"]):\n",
        "        return \"greeting_response\"\n",
        "\n",
        "    # Check if this requires a tool\n",
        "    if any(keyword in last_message for keyword in [\"search for\", \"look up\", \"wikipedia\", \"current time\", \"save conversation\", \"load\", \"knowledge base\"]):\n",
        "        # Note: \"search for\" might no longer be routed to a tool if DuckDuckGo is removed,\n",
        "        # but Wikipedia still handles \"look up\" and \"wikipedia\".\n",
        "        # Also removed keywords for tools that require state access\n",
        "        if any(keyword in last_message for keyword in [\"save conversation\", \"load\", \"knowledge base\"]):\n",
        "            return \"general_response\" # Route state-dependent tool calls to general response for now\n",
        "\n",
        "        return \"use_tool\"\n",
        "\n",
        "    # Check if this needs clarification\n",
        "    if state.get(\"needs_clarification\", False):\n",
        "        return \"ask_clarification\"\n",
        "\n",
        "    # Default to general response\n",
        "    return \"general_response\"\n",
        "\n",
        "# Define node functions\n",
        "def greeting_response(state: AgentState):\n",
        "    \"\"\"Generates a greeting response.\"\"\"\n",
        "    response = \"Hello! I'm your AI assistant. How can I help you today?\"\n",
        "    state[\"messages\"].append(AIMessage(content=response))\n",
        "    return state\n",
        "\n",
        "def use_tool(state: AgentState):\n",
        "    \"\"\"Uses tools to respond to the user.\"\"\"\n",
        "    try:\n",
        "        # Get the last human message\n",
        "        input_text = state[\"messages\"][-1].content\n",
        "\n",
        "        # Run the agent with tools\n",
        "        result = agent_executor.invoke({\"input\": input_text, \"messages\": state[\"messages\"]})\n",
        "\n",
        "        # Add the response to the messages\n",
        "        state[\"messages\"].append(AIMessage(content=result[\"output\"]))\n",
        "\n",
        "        # Update conversation topic if needed\n",
        "        if not state.get(\"current_topic\"):\n",
        "            state[\"current_topic\"] = \"general inquiry\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"I encountered an error: {str(e)}. Please try again.\"\n",
        "        state[\"messages\"].append(AIMessage(content=error_msg))\n",
        "\n",
        "    return state\n",
        "\n",
        "def ask_clarification(state: AgentState):\n",
        "    \"\"\"Asks for clarification when needed.\"\"\"\n",
        "    clarification_question = state.get(\"clarification_question\", \"Could you please clarify what you mean?\")\n",
        "    state[\"messages\"].append(AIMessage(content=clarification_question))\n",
        "    state[\"needs_clarification\"] = False\n",
        "    state[\"clarification_question\"] = None\n",
        "    return state\n",
        "\n",
        "def general_response(state: AgentState):\n",
        "    \"\"\"Generates a general response using the LLM.\"\"\"\n",
        "    try:\n",
        "        # Use the LLM to generate a response\n",
        "        messages = state[\"messages\"]\n",
        "\n",
        "        # Create a prompt for the LLM\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"You are a helpful AI assistant. Continue the conversation naturally based on the history.\"),\n",
        "            MessagesPlaceholder(variable_name=\"messages\")\n",
        "        ])\n",
        "\n",
        "        # Use Gemini for general responses\n",
        "        chain = prompt | llm_gemini | StrOutputParser()\n",
        "        response = chain.invoke({\"messages\": messages})\n",
        "\n",
        "        # Add to messages\n",
        "        state[\"messages\"].append(AIMessage(content=response))\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"I encountered an error: {str(e)}. Please try again.\"\n",
        "        state[\"messages\"].append(AIMessage(content=error_msg))\n",
        "\n",
        "    return state\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"greeting_response\", greeting_response)\n",
        "workflow.add_node(\"use_tool\", use_tool)\n",
        "workflow.add_node(\"ask_clarification\", ask_clarification)\n",
        "workflow.add_node(\"general_response\", general_response)\n",
        "\n",
        "# Add edges\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_conversation,\n",
        "    {\n",
        "        \"greeting_response\": \"greeting_response\",\n",
        "        \"use_tool\": \"use_tool\",\n",
        "        \"ask_clarification\": \"ask_clarification\",\n",
        "        \"general_response\": \"general_response\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"greeting_response\", END)\n",
        "workflow.add_edge(\"use_tool\", END)\n",
        "workflow.add_edge(\"ask_clarification\", END)\n",
        "workflow.add_edge(\"general_response\", END) # Changed to add_edge\n",
        "\n",
        "\n",
        "# Compile the graph\n",
        "# memory = SqliteSaver.from_conn_string(\":memory:\") # Removed SqliteSaver initialization\n",
        "app = workflow.compile() # Removed checkpointer argument\n",
        "\n",
        "# Chat interface\n",
        "def chat_interface():\n",
        "    print(\" Welcome to the Advanced AI Assistant!\")\n",
        "    print(\"I can help with various tasks, answer questions, search the web, and more.\")\n",
        "    print(\"Type 'quit' or 'exit' to end the conversation.\\n\")\n",
        "\n",
        "    # Initialize conversation\n",
        "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "    state = {\n",
        "        \"messages\": [],\n",
        "        \"current_topic\": \"\",\n",
        "        \"conversation_history\": [],\n",
        "        \"user_profile\": {},\n",
        "        \"knowledge_base\": None,\n",
        "        \"needs_clarification\": False,\n",
        "        \"clarification_question\": None\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "            print(\"AI: Goodbye! It was nice chatting with you.\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        # Add user message to state\n",
        "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
        "\n",
        "        # Invoke the graph\n",
        "        try:\n",
        "            # Pass the config to the invoke call\n",
        "            result = app.invoke(state, config)\n",
        "            state = result\n",
        "\n",
        "            # Print the last AI response\n",
        "            if state[\"messages\"] and isinstance(state[\"messages\"][-1], AIMessage):\n",
        "                print(f\"AI: {state['messages'][-1].content}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"AI: I encountered an error: {str(e)}. Please try again.\")\n",
        "\n",
        "        print()  # Empty line for readability\n",
        "\n",
        "# Run the chat interface\n",
        "if __name__ == \"__main__\":\n",
        "    chat_interface()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Welcome to the Advanced AI Assistant!\n",
            "I can help with various tasks, answer questions, search the web, and more.\n",
            "Type 'quit' or 'exit' to end the conversation.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2101979131.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;31m# Run the chat interface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mchat_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2101979131.py\u001b[0m in \u001b[0;36mchat_interface\u001b[0;34m()\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}